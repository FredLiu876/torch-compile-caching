//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_poi_fused_clone_6 // -- Begin function triton_poi_fused_clone_6
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
                                        // @triton_poi_fused_clone_6
.visible .entry triton_poi_fused_clone_6(
	.param .u64 .ptr .global .align 1 triton_poi_fused_clone_6_param_0,
	.param .u64 .ptr .global .align 1 triton_poi_fused_clone_6_param_1,
	.param .u64 .ptr .global .align 1 triton_poi_fused_clone_6_param_2,
	.param .u32 triton_poi_fused_clone_6_param_3,
	.param .u32 triton_poi_fused_clone_6_param_4,
	.param .u64 .ptr .global .align 1 triton_poi_fused_clone_6_param_5
)
.reqntid 128, 1, 1
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<229>;
	.reg .b16 	%rs<81>;
	.reg .b32 	%r<1307>;
	.reg .f32 	%f<1113>;
	.reg .b64 	%rd<341>;
	.reg .f64 	%fd<49>;
	.loc	1 18 0                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:18:0
$L__func_begin0:
	.loc	1 18 0                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:18:0

// %bb.0:
	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd58, [triton_poi_fused_clone_6_param_0];
	ld.param.u64 	%rd78, [triton_poi_fused_clone_6_param_1];
	add.u64 	%rd80, %SPL, 0;
	ld.param.u32 	%r466, [triton_poi_fused_clone_6_param_3];
	add.u64 	%rd82, %SPL, 0;
	add.u64 	%rd84, %SPL, 0;
	add.u64 	%rd86, %SPL, 0;
	add.u64 	%rd88, %SPL, 0;
	add.u64 	%rd90, %SPL, 0;
	add.u64 	%rd92, %SPL, 0;
	add.u64 	%rd94, %SPL, 0;
	add.u64 	%rd96, %SPL, 0;
	add.u64 	%rd98, %SPL, 0;
	add.u64 	%rd100, %SPL, 0;
	add.u64 	%rd102, %SPL, 0;
	add.u64 	%rd104, %SPL, 0;
	add.u64 	%rd106, %SPL, 0;
	add.u64 	%rd108, %SPL, 0;
	add.u64 	%rd110, %SPL, 0;
	add.u64 	%rd112, %SPL, 0;
	add.u64 	%rd114, %SPL, 0;
	add.u64 	%rd116, %SPL, 0;
	add.u64 	%rd118, %SPL, 0;
	add.u64 	%rd120, %SPL, 0;
	add.u64 	%rd122, %SPL, 0;
	add.u64 	%rd124, %SPL, 0;
	add.u64 	%rd126, %SPL, 0;
$L__tmp0:
	.loc	1 19 28                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:19:28
	mov.u32 	%r467, %ctaid.x;
	.loc	1 19 33                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:19:33
	shl.b32 	%r468, %r467, 10;
	.loc	1 20 36                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:20:36
	mov.u32 	%r469, %tid.x;
	shl.b32 	%r470, %r469, 3;
	and.b32  	%r471, %r470, 1016;
	.loc	1 20 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:20:23
	or.b32  	%r472, %r471, %r468;
	or.b32  	%r473, %r472, 1;
	or.b32  	%r474, %r472, 2;
	or.b32  	%r475, %r472, 3;
	or.b32  	%r476, %r472, 4;
	or.b32  	%r477, %r472, 5;
	or.b32  	%r478, %r472, 6;
	or.b32  	%r479, %r472, 7;
	.loc	1 22 19                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:22:19
	bfe.s32 	%r480, %r467, 21, 1;
	shr.u32 	%r481, %r480, 25;
	add.s32 	%r482, %r472, %r481;
	and.b32  	%r483, %r482, -128;
	sub.s32 	%r25, %r472, %r483;
	add.s32 	%r484, %r473, %r481;
	and.b32  	%r485, %r484, 65408;
	sub.s32 	%r486, %r473, %r485;
	add.s32 	%r487, %r474, %r481;
	and.b32  	%r488, %r487, 65408;
	sub.s32 	%r489, %r474, %r488;
	add.s32 	%r490, %r475, %r481;
	and.b32  	%r491, %r490, 65408;
	sub.s32 	%r492, %r475, %r491;
	add.s32 	%r493, %r476, %r481;
	and.b32  	%r494, %r493, 65408;
	sub.s32 	%r495, %r476, %r494;
	add.s32 	%r496, %r477, %r481;
	and.b32  	%r497, %r496, 65408;
	sub.s32 	%r498, %r477, %r497;
	add.s32 	%r499, %r478, %r481;
	and.b32  	%r500, %r499, 65408;
	sub.s32 	%r501, %r478, %r500;
	add.s32 	%r502, %r479, %r481;
	and.b32  	%r503, %r502, 65408;
	sub.s32 	%r504, %r479, %r503;
	.loc	1 24 19                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:24:19
	shr.u32 	%r505, %r480, 20;
	add.s32 	%r506, %r472, %r505;
	shr.s32 	%r507, %r506, 12;
	.loc	1 25 31                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:31
	mul.wide.s32 	%rd127, %r472, 2;
	add.s64 	%rd60, %rd58, %rd127;
	.loc	1 25 36                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:36
	// begin inline asm
	mov.u32 %r430, 0x0;
	mov.u32 %r431, 0x0;
	mov.u32 %r432, 0x0;
	mov.u32 %r433, 0x0;
	ld.global.v4.b32 { %r430, %r431, %r432, %r433 }, [ %rd60 + 0 ];
	// end inline asm
	.loc	1 26 47                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:26:47
	cvt.u16.u32 	%rs1, %r25;
	cvt.s8.s32 	%rs2, %r25;
	shr.u16 	%rs3, %rs2, 9;
	and.b16  	%rs4, %rs3, 63;
	add.s16 	%rs5, %rs1, %rs4;
	and.b16  	%rs6, %rs5, 192;
	sub.s16 	%rs7, %rs1, %rs6;
	cvt.u32.u16 	%r508, %rs7;
	cvt.s32.s8 	%r509, %r508;
	cvt.u16.u32 	%rs8, %r486;
	cvt.s8.s32 	%rs9, %r486;
	shr.u16 	%rs10, %rs9, 9;
	and.b16  	%rs11, %rs10, 63;
	add.s16 	%rs12, %rs8, %rs11;
	and.b16  	%rs13, %rs12, 192;
	sub.s16 	%rs14, %rs8, %rs13;
	cvt.u32.u16 	%r510, %rs14;
	cvt.s32.s8 	%r511, %r510;
	cvt.u16.u32 	%rs15, %r489;
	cvt.s8.s32 	%rs16, %r489;
	shr.u16 	%rs17, %rs16, 9;
	and.b16  	%rs18, %rs17, 63;
	add.s16 	%rs19, %rs15, %rs18;
	and.b16  	%rs20, %rs19, 192;
	sub.s16 	%rs21, %rs15, %rs20;
	cvt.u32.u16 	%r512, %rs21;
	cvt.s32.s8 	%r513, %r512;
	cvt.u16.u32 	%rs22, %r492;
	cvt.s8.s32 	%rs23, %r492;
	shr.u16 	%rs24, %rs23, 9;
	and.b16  	%rs25, %rs24, 63;
	add.s16 	%rs26, %rs22, %rs25;
	and.b16  	%rs27, %rs26, 192;
	sub.s16 	%rs28, %rs22, %rs27;
	cvt.u32.u16 	%r514, %rs28;
	cvt.s32.s8 	%r515, %r514;
	cvt.u16.u32 	%rs29, %r495;
	cvt.s8.s32 	%rs30, %r495;
	shr.u16 	%rs31, %rs30, 9;
	and.b16  	%rs32, %rs31, 63;
	add.s16 	%rs33, %rs29, %rs32;
	and.b16  	%rs34, %rs33, 192;
	sub.s16 	%rs35, %rs29, %rs34;
	cvt.u32.u16 	%r516, %rs35;
	cvt.s32.s8 	%r517, %r516;
	cvt.u16.u32 	%rs36, %r498;
	cvt.s8.s32 	%rs37, %r498;
	shr.u16 	%rs38, %rs37, 9;
	and.b16  	%rs39, %rs38, 63;
	add.s16 	%rs40, %rs36, %rs39;
	and.b16  	%rs41, %rs40, 192;
	sub.s16 	%rs42, %rs36, %rs41;
	cvt.u32.u16 	%r518, %rs42;
	cvt.s32.s8 	%r519, %r518;
	cvt.u16.u32 	%rs43, %r501;
	cvt.s8.s32 	%rs44, %r501;
	shr.u16 	%rs45, %rs44, 9;
	and.b16  	%rs46, %rs45, 63;
	add.s16 	%rs47, %rs43, %rs46;
	and.b16  	%rs48, %rs47, 192;
	sub.s16 	%rs49, %rs43, %rs48;
	cvt.u32.u16 	%r520, %rs49;
	cvt.s32.s8 	%r521, %r520;
	cvt.u16.u32 	%rs50, %r504;
	cvt.s8.s32 	%rs51, %r504;
	shr.u16 	%rs52, %rs51, 9;
	and.b16  	%rs53, %rs52, 63;
	add.s16 	%rs54, %rs50, %rs53;
	and.b16  	%rs55, %rs54, 192;
	sub.s16 	%rs56, %rs50, %rs55;
	cvt.u32.u16 	%r522, %rs56;
	cvt.s32.s8 	%r523, %r522;
	.loc	1 26 36                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:26:36
	mad.lo.s32 	%r524, %r466, %r509, %r507;
	mad.lo.s32 	%r525, %r466, %r511, %r507;
	mad.lo.s32 	%r526, %r466, %r513, %r507;
	mad.lo.s32 	%r527, %r466, %r515, %r507;
	mad.lo.s32 	%r528, %r466, %r517, %r507;
	mad.lo.s32 	%r529, %r466, %r519, %r507;
	mad.lo.s32 	%r530, %r466, %r521, %r507;
	mad.lo.s32 	%r531, %r466, %r523, %r507;
	.loc	1 26 31                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:26:31
	mul.wide.s32 	%rd128, %r524, 4;
	add.s64 	%rd61, %rd78, %rd128;
	mul.wide.s32 	%rd129, %r525, 4;
	add.s64 	%rd62, %rd78, %rd129;
	mul.wide.s32 	%rd130, %r526, 4;
	add.s64 	%rd63, %rd78, %rd130;
	mul.wide.s32 	%rd131, %r527, 4;
	add.s64 	%rd64, %rd78, %rd131;
	mul.wide.s32 	%rd132, %r528, 4;
	add.s64 	%rd65, %rd78, %rd132;
	mul.wide.s32 	%rd133, %r529, 4;
	add.s64 	%rd66, %rd78, %rd133;
	mul.wide.s32 	%rd134, %r530, 4;
	add.s64 	%rd67, %rd78, %rd134;
	mul.wide.s32 	%rd135, %r531, 4;
	add.s64 	%rd68, %rd78, %rd135;
	.loc	1 26 54                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:26:54
	// begin inline asm
	mov.u32 %r434, 0x0;
	ld.global.L1::evict_last.b32 { %r434 }, [ %rd61 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r435, 0x0;
	ld.global.L1::evict_last.b32 { %r435 }, [ %rd62 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r436, 0x0;
	ld.global.L1::evict_last.b32 { %r436 }, [ %rd63 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r437, 0x0;
	ld.global.L1::evict_last.b32 { %r437 }, [ %rd64 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r438, 0x0;
	ld.global.L1::evict_last.b32 { %r438 }, [ %rd65 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r439, 0x0;
	ld.global.L1::evict_last.b32 { %r439 }, [ %rd66 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r440, 0x0;
	ld.global.L1::evict_last.b32 { %r440 }, [ %rd67 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r441, 0x0;
	ld.global.L1::evict_last.b32 { %r441 }, [ %rd68 + 0 ];
	// end inline asm
	.loc	1 29 19                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:29:19
	setp.gt.s32 	%p1, %r25, 63;
	.loc	1 30 38                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:38
	add.s32 	%r532, %r472, -64;
	.loc	1 30 30                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:30
	mul.wide.s32 	%rd136, %r532, 2;
	add.s64 	%rd69, %rd58, %rd136;
	mov.b32 	%r446, 0;
	.loc	1 30 43                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:43
	// begin inline asm
	mov.u32 %r442, %r446;
	mov.u32 %r443, %r446;
	mov.u32 %r444, %r446;
	mov.u32 %r445, %r446;
	@%p1 ld.global.v4.b32 { %r442, %r443, %r444, %r445 }, [ %rd69 + 0 ];
	// end inline asm
	.loc	1 31 53                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:31:53
	// begin inline asm
	mov.u32 %r450, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r450 }, [ %rd61 + 0 ];
	// end inline asm
	mov.b32 	%f9, %r450;
	// begin inline asm
	mov.u32 %r452, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r452 }, [ %rd62 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r454, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r454 }, [ %rd63 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r456, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r456 }, [ %rd64 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r458, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r458 }, [ %rd65 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r460, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r460 }, [ %rd66 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r462, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r462 }, [ %rd67 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r464, %r446;
	@%p1 ld.global.L1::evict_last.b32 { %r464 }, [ %rd68 + 0 ];
	// end inline asm
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f385, %f9, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1214, %f385;
	cvt.rn.f32.s32 	%f386, %r1214;
	mov.f32 	%f387, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f388, %f386, %f387, %f9;
	mov.f32 	%f389, 0fB3A22168;
	fma.rn.ftz.f32 	%f390, %f386, %f389, %f388;
	mov.f32 	%f391, 0fA7C234C5;
	fma.rn.ftz.f32 	%f993, %f386, %f391, %f390;
	abs.ftz.f32 	%f18, %f9;
	setp.ltu.f32 	%p10, %f18, 0f47CE4780;
	@%p10 bra 	$L__BB0_8;
// %bb.1:                               // %__nv_isinff.exit.i.i.i
	setp.neu.f32 	%p11, %f18, 0f7F800000;
	@%p11 bra 	$L__BB0_3;
// %bb.2:                               // %__nv_fmul_rn.exit.i.i.i
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f394, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f993, %f9, %f394;
	mov.b32 	%r1214, 0;
	bra.uni 	$L__BB0_8;
$L__BB0_3:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r24, %rd126;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r51, %r450, 23;
	and.b32  	%r534, %r51, 224;
	add.s32 	%r535, %r534, -128;
	shl.b32 	%r536, %r450, 8;
	or.b32  	%r540, %r536, -2147483648;
	shr.u32 	%r53, %r535, 5;
	mov.b32 	%r1212, 0;
	mov.b64 	%rd317, 0;
	mov.u64 	%rd138, __cudart_i2opi_f;
	mov.u32 	%r1211, %r24;
$L__BB0_4:                              // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd139, %rd138, %rd317;
	ld.global.nc.u32 	%r539, [%rd139];
	// begin inline asm
	{
	mad.lo.cc.u32   %r537, %r539, %r540, %r1212;
	madc.hi.u32     %r1212, %r539, %r540,  0;
	}
	// end inline asm
	st.local.u32 	[%r1211], %r537;
	add.s32 	%r1211, %r1211, 4;
	add.s64 	%rd317, %rd317, 4;
	setp.ne.s64 	%p12, %rd317, 24;
	@%p12 bra 	$L__BB0_4;
// %bb.5:
	st.local.u32 	[%r24+24], %r1212;
	shl.b32 	%r542, %r53, 2;
	sub.s32 	%r58, %r24, %r542;
	ld.local.u32 	%r59, [%r58+24];
	ld.local.u32 	%r60, [%r58+20];
	and.b32  	%r544, %r450, 260046848;
	setp.eq.s32 	%p13, %r544, 0;
	mov.u32 	%r1213, %r60;
	@%p13 bra 	$L__BB0_7;
// %bb.6:
	ld.local.u32 	%r545, [%r58+16];
	shf.l.wrap.b32 	%r1213, %r545, %r60, %r51;
$L__BB0_7:                              // %__internal_trig_reduction_slowpath.exit.i.i.i
	shf.l.wrap.b32 	%r546, %r60, %r59, %r51;
	shr.u32 	%r547, %r546, 30;
	shf.l.wrap.b32 	%r548, %r1213, %r546, 2;
	shl.b32 	%r549, %r1213, 2;
	shr.u32 	%r550, %r548, 31;
	add.s32 	%r551, %r550, %r547;
	neg.s32 	%r552, %r551;
	setp.lt.s32 	%p14, %r450, 0;
	selp.b32 	%r1214, %r552, %r551, %p14;
	xor.b32  	%r553, %r548, %r450;
	shr.s32 	%r554, %r548, 31;
	xor.b32  	%r555, %r554, %r548;
	xor.b32  	%r556, %r554, %r549;
	cvt.u64.u32 	%rd140, %r555;
	shl.b64 	%rd141, %rd140, 32;
	cvt.u64.u32 	%rd142, %r556;
	or.b64  	%rd143, %rd141, %rd142;
	cvt.rn.f64.s64 	%fd1, %rd143;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f392, %fd2;
	neg.f32 	%f393, %f392;
	setp.lt.s32 	%p15, %r553, 0;
	selp.f32 	%f993, %f393, %f392, %p15;
$L__BB0_8:                              // %__internal_trig_reduction_kernel.exit.i.i
	mul.rn.ftz.f32 	%f22, %f993, %f993;
	and.b32  	%r558, %r1214, 1;
	setp.eq.b32 	%p16, %r558, 1;
	not.pred 	%p17, %p16;
	selp.f32 	%f23, 0f3F800000, %f993, %p16;
	mov.f32 	%f398, 0f00000000;
	fma.rn.ftz.f32 	%f24, %f22, %f23, %f398;
	mov.f32 	%f996, 0fB94D4153;
	mov.f32 	%f995, 0f3C0885E4;
	mov.f32 	%f994, 0fBE2AAAA8;
	@%p17 bra 	$L__BB0_10;
// %bb.9:                               // %__internal_fmad.exit1.i.i.i
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f399, 0fBAB607ED;
	mov.f32 	%f400, 0f37CBAC00;
	fma.rn.ftz.f32 	%f996, %f400, %f22, %f399;
	mov.f32 	%f995, 0f3D2AAABB;
	mov.f32 	%f994, 0fBEFFFFFF;
$L__BB0_10:                             // %__internal_fmad.exit2.i.i.i
	mov.b32 	%f10, %r452;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f403, %f996, %f22, %f995;
	fma.rn.ftz.f32 	%f404, %f403, %f22, %f994;
	fma.rn.ftz.f32 	%f997, %f404, %f24, %f23;
	and.b32  	%r559, %r1214, 2;
	setp.eq.s32 	%p18, %r559, 0;
	@%p18 bra 	$L__BB0_12;
// %bb.11:                              // %__internal_fmad.exit5.i.i.i
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f406, 0fBF800000;
	fma.rn.ftz.f32 	%f997, %f997, %f406, %f398;
$L__BB0_12:                             // %__nv_sinf.exit
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f407, %f10, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1218, %f407;
	cvt.rn.f32.s32 	%f408, %r1218;
	mov.f32 	%f409, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f410, %f408, %f409, %f10;
	mov.f32 	%f411, 0fB3A22168;
	fma.rn.ftz.f32 	%f412, %f408, %f411, %f410;
	mov.f32 	%f413, 0fA7C234C5;
	fma.rn.ftz.f32 	%f998, %f408, %f413, %f412;
	abs.ftz.f32 	%f33, %f10;
	setp.ltu.f32 	%p19, %f33, 0f47CE4780;
	@%p19 bra 	$L__BB0_20;
// %bb.13:                              // %__nv_isinff.exit.i.i.i12
	setp.neu.f32 	%p20, %f33, 0f7F800000;
	@%p20 bra 	$L__BB0_15;
// %bb.14:                              // %__nv_fmul_rn.exit.i.i.i52
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f416, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f998, %f10, %f416;
	mov.b32 	%r1218, 0;
	bra.uni 	$L__BB0_20;
$L__BB0_15:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r23, %rd124;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r66, %r452, 23;
	and.b32  	%r561, %r66, 224;
	add.s32 	%r562, %r561, -128;
	shl.b32 	%r563, %r452, 8;
	or.b32  	%r567, %r563, -2147483648;
	shr.u32 	%r68, %r562, 5;
	mov.b32 	%r1216, 0;
	mov.b64 	%rd318, 0;
	mov.u64 	%rd145, __cudart_i2opi_f;
	mov.u32 	%r1215, %r23;
$L__BB0_16:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd146, %rd145, %rd318;
	ld.global.nc.u32 	%r566, [%rd146];
	// begin inline asm
	{
	mad.lo.cc.u32   %r564, %r566, %r567, %r1216;
	madc.hi.u32     %r1216, %r566, %r567,  0;
	}
	// end inline asm
	st.local.u32 	[%r1215], %r564;
	add.s32 	%r1215, %r1215, 4;
	add.s64 	%rd318, %rd318, 4;
	setp.ne.s64 	%p21, %rd318, 24;
	@%p21 bra 	$L__BB0_16;
// %bb.17:
	st.local.u32 	[%r23+24], %r1216;
	shl.b32 	%r569, %r68, 2;
	sub.s32 	%r73, %r23, %r569;
	ld.local.u32 	%r74, [%r73+24];
	ld.local.u32 	%r75, [%r73+20];
	and.b32  	%r571, %r452, 260046848;
	setp.eq.s32 	%p22, %r571, 0;
	mov.u32 	%r1217, %r75;
	@%p22 bra 	$L__BB0_19;
// %bb.18:
	ld.local.u32 	%r572, [%r73+16];
	shf.l.wrap.b32 	%r1217, %r572, %r75, %r66;
$L__BB0_19:                             // %__internal_trig_reduction_slowpath.exit.i.i.i18
	shf.l.wrap.b32 	%r573, %r75, %r74, %r66;
	shr.u32 	%r574, %r573, 30;
	shf.l.wrap.b32 	%r575, %r1217, %r573, 2;
	shl.b32 	%r576, %r1217, 2;
	shr.u32 	%r577, %r575, 31;
	add.s32 	%r578, %r577, %r574;
	neg.s32 	%r579, %r578;
	setp.lt.s32 	%p23, %r452, 0;
	selp.b32 	%r1218, %r579, %r578, %p23;
	xor.b32  	%r580, %r575, %r452;
	shr.s32 	%r581, %r575, 31;
	xor.b32  	%r582, %r581, %r575;
	xor.b32  	%r583, %r581, %r576;
	cvt.u64.u32 	%rd147, %r582;
	shl.b64 	%rd148, %rd147, 32;
	cvt.u64.u32 	%rd149, %r583;
	or.b64  	%rd150, %rd148, %rd149;
	cvt.rn.f64.s64 	%fd3, %rd150;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f414, %fd4;
	neg.f32 	%f415, %f414;
	setp.lt.s32 	%p24, %r580, 0;
	selp.f32 	%f998, %f415, %f414, %p24;
$L__BB0_20:                             // %__internal_trig_reduction_kernel.exit.i.i29
	mul.rn.ftz.f32 	%f37, %f998, %f998;
	and.b32  	%r585, %r1218, 1;
	setp.eq.b32 	%p25, %r585, 1;
	not.pred 	%p26, %p25;
	selp.f32 	%f38, 0f3F800000, %f998, %p25;
	mov.f32 	%f420, 0f00000000;
	fma.rn.ftz.f32 	%f39, %f37, %f38, %f420;
	mov.f32 	%f1001, 0fB94D4153;
	mov.f32 	%f1000, 0f3C0885E4;
	mov.f32 	%f999, 0fBE2AAAA8;
	@%p26 bra 	$L__BB0_22;
// %bb.21:                              // %__internal_fmad.exit1.i.i.i37
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f421, 0fBAB607ED;
	mov.f32 	%f422, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1001, %f422, %f37, %f421;
	mov.f32 	%f1000, 0f3D2AAABB;
	mov.f32 	%f999, 0fBEFFFFFF;
$L__BB0_22:                             // %__internal_fmad.exit2.i.i.i40
	mov.b32 	%f11, %r454;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f425, %f1001, %f37, %f1000;
	fma.rn.ftz.f32 	%f426, %f425, %f37, %f999;
	fma.rn.ftz.f32 	%f1002, %f426, %f39, %f38;
	and.b32  	%r586, %r1218, 2;
	setp.eq.s32 	%p27, %r586, 0;
	@%p27 bra 	$L__BB0_24;
// %bb.23:                              // %__internal_fmad.exit5.i.i.i48
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f428, 0fBF800000;
	fma.rn.ftz.f32 	%f1002, %f1002, %f428, %f420;
$L__BB0_24:                             // %__nv_sinf.exit55
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f429, %f11, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1222, %f429;
	cvt.rn.f32.s32 	%f430, %r1222;
	mov.f32 	%f431, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f432, %f430, %f431, %f11;
	mov.f32 	%f433, 0fB3A22168;
	fma.rn.ftz.f32 	%f434, %f430, %f433, %f432;
	mov.f32 	%f435, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1003, %f430, %f435, %f434;
	abs.ftz.f32 	%f48, %f11;
	setp.ltu.f32 	%p28, %f48, 0f47CE4780;
	@%p28 bra 	$L__BB0_32;
// %bb.25:                              // %__nv_isinff.exit.i.i.i67
	setp.neu.f32 	%p29, %f48, 0f7F800000;
	@%p29 bra 	$L__BB0_27;
// %bb.26:                              // %__nv_fmul_rn.exit.i.i.i107
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f438, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1003, %f11, %f438;
	mov.b32 	%r1222, 0;
	bra.uni 	$L__BB0_32;
$L__BB0_27:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r22, %rd122;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r81, %r454, 23;
	and.b32  	%r588, %r81, 224;
	add.s32 	%r589, %r588, -128;
	shl.b32 	%r590, %r454, 8;
	or.b32  	%r594, %r590, -2147483648;
	shr.u32 	%r83, %r589, 5;
	mov.b32 	%r1220, 0;
	mov.b64 	%rd319, 0;
	mov.u64 	%rd152, __cudart_i2opi_f;
	mov.u32 	%r1219, %r22;
$L__BB0_28:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd153, %rd152, %rd319;
	ld.global.nc.u32 	%r593, [%rd153];
	// begin inline asm
	{
	mad.lo.cc.u32   %r591, %r593, %r594, %r1220;
	madc.hi.u32     %r1220, %r593, %r594,  0;
	}
	// end inline asm
	st.local.u32 	[%r1219], %r591;
	add.s32 	%r1219, %r1219, 4;
	add.s64 	%rd319, %rd319, 4;
	setp.ne.s64 	%p30, %rd319, 24;
	@%p30 bra 	$L__BB0_28;
// %bb.29:
	st.local.u32 	[%r22+24], %r1220;
	shl.b32 	%r596, %r83, 2;
	sub.s32 	%r88, %r22, %r596;
	ld.local.u32 	%r89, [%r88+24];
	ld.local.u32 	%r90, [%r88+20];
	and.b32  	%r598, %r454, 260046848;
	setp.eq.s32 	%p31, %r598, 0;
	mov.u32 	%r1221, %r90;
	@%p31 bra 	$L__BB0_31;
// %bb.30:
	ld.local.u32 	%r599, [%r88+16];
	shf.l.wrap.b32 	%r1221, %r599, %r90, %r81;
$L__BB0_31:                             // %__internal_trig_reduction_slowpath.exit.i.i.i73
	shf.l.wrap.b32 	%r600, %r90, %r89, %r81;
	shr.u32 	%r601, %r600, 30;
	shf.l.wrap.b32 	%r602, %r1221, %r600, 2;
	shl.b32 	%r603, %r1221, 2;
	shr.u32 	%r604, %r602, 31;
	add.s32 	%r605, %r604, %r601;
	neg.s32 	%r606, %r605;
	setp.lt.s32 	%p32, %r454, 0;
	selp.b32 	%r1222, %r606, %r605, %p32;
	xor.b32  	%r607, %r602, %r454;
	shr.s32 	%r608, %r602, 31;
	xor.b32  	%r609, %r608, %r602;
	xor.b32  	%r610, %r608, %r603;
	cvt.u64.u32 	%rd154, %r609;
	shl.b64 	%rd155, %rd154, 32;
	cvt.u64.u32 	%rd156, %r610;
	or.b64  	%rd157, %rd155, %rd156;
	cvt.rn.f64.s64 	%fd5, %rd157;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f436, %fd6;
	neg.f32 	%f437, %f436;
	setp.lt.s32 	%p33, %r607, 0;
	selp.f32 	%f1003, %f437, %f436, %p33;
$L__BB0_32:                             // %__internal_trig_reduction_kernel.exit.i.i84
	mul.rn.ftz.f32 	%f52, %f1003, %f1003;
	and.b32  	%r612, %r1222, 1;
	setp.eq.b32 	%p34, %r612, 1;
	not.pred 	%p35, %p34;
	selp.f32 	%f53, 0f3F800000, %f1003, %p34;
	mov.f32 	%f442, 0f00000000;
	fma.rn.ftz.f32 	%f54, %f52, %f53, %f442;
	mov.f32 	%f1006, 0fB94D4153;
	mov.f32 	%f1005, 0f3C0885E4;
	mov.f32 	%f1004, 0fBE2AAAA8;
	@%p35 bra 	$L__BB0_34;
// %bb.33:                              // %__internal_fmad.exit1.i.i.i92
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f443, 0fBAB607ED;
	mov.f32 	%f444, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1006, %f444, %f52, %f443;
	mov.f32 	%f1005, 0f3D2AAABB;
	mov.f32 	%f1004, 0fBEFFFFFF;
$L__BB0_34:                             // %__internal_fmad.exit2.i.i.i95
	mov.b32 	%f12, %r456;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f447, %f1006, %f52, %f1005;
	fma.rn.ftz.f32 	%f448, %f447, %f52, %f1004;
	fma.rn.ftz.f32 	%f1007, %f448, %f54, %f53;
	and.b32  	%r613, %r1222, 2;
	setp.eq.s32 	%p36, %r613, 0;
	@%p36 bra 	$L__BB0_36;
// %bb.35:                              // %__internal_fmad.exit5.i.i.i103
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f450, 0fBF800000;
	fma.rn.ftz.f32 	%f1007, %f1007, %f450, %f442;
$L__BB0_36:                             // %__nv_sinf.exit110
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f451, %f12, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1226, %f451;
	cvt.rn.f32.s32 	%f452, %r1226;
	mov.f32 	%f453, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f454, %f452, %f453, %f12;
	mov.f32 	%f455, 0fB3A22168;
	fma.rn.ftz.f32 	%f456, %f452, %f455, %f454;
	mov.f32 	%f457, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1008, %f452, %f457, %f456;
	abs.ftz.f32 	%f63, %f12;
	setp.ltu.f32 	%p37, %f63, 0f47CE4780;
	@%p37 bra 	$L__BB0_44;
// %bb.37:                              // %__nv_isinff.exit.i.i.i122
	setp.neu.f32 	%p38, %f63, 0f7F800000;
	@%p38 bra 	$L__BB0_39;
// %bb.38:                              // %__nv_fmul_rn.exit.i.i.i162
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f460, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1008, %f12, %f460;
	mov.b32 	%r1226, 0;
	bra.uni 	$L__BB0_44;
$L__BB0_39:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r21, %rd120;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r96, %r456, 23;
	and.b32  	%r615, %r96, 224;
	add.s32 	%r616, %r615, -128;
	shl.b32 	%r617, %r456, 8;
	or.b32  	%r621, %r617, -2147483648;
	shr.u32 	%r98, %r616, 5;
	mov.b32 	%r1224, 0;
	mov.b64 	%rd320, 0;
	mov.u64 	%rd159, __cudart_i2opi_f;
	mov.u32 	%r1223, %r21;
$L__BB0_40:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd160, %rd159, %rd320;
	ld.global.nc.u32 	%r620, [%rd160];
	// begin inline asm
	{
	mad.lo.cc.u32   %r618, %r620, %r621, %r1224;
	madc.hi.u32     %r1224, %r620, %r621,  0;
	}
	// end inline asm
	st.local.u32 	[%r1223], %r618;
	add.s32 	%r1223, %r1223, 4;
	add.s64 	%rd320, %rd320, 4;
	setp.ne.s64 	%p39, %rd320, 24;
	@%p39 bra 	$L__BB0_40;
// %bb.41:
	st.local.u32 	[%r21+24], %r1224;
	shl.b32 	%r623, %r98, 2;
	sub.s32 	%r103, %r21, %r623;
	ld.local.u32 	%r104, [%r103+24];
	ld.local.u32 	%r105, [%r103+20];
	and.b32  	%r625, %r456, 260046848;
	setp.eq.s32 	%p40, %r625, 0;
	mov.u32 	%r1225, %r105;
	@%p40 bra 	$L__BB0_43;
// %bb.42:
	ld.local.u32 	%r626, [%r103+16];
	shf.l.wrap.b32 	%r1225, %r626, %r105, %r96;
$L__BB0_43:                             // %__internal_trig_reduction_slowpath.exit.i.i.i128
	shf.l.wrap.b32 	%r627, %r105, %r104, %r96;
	shr.u32 	%r628, %r627, 30;
	shf.l.wrap.b32 	%r629, %r1225, %r627, 2;
	shl.b32 	%r630, %r1225, 2;
	shr.u32 	%r631, %r629, 31;
	add.s32 	%r632, %r631, %r628;
	neg.s32 	%r633, %r632;
	setp.lt.s32 	%p41, %r456, 0;
	selp.b32 	%r1226, %r633, %r632, %p41;
	xor.b32  	%r634, %r629, %r456;
	shr.s32 	%r635, %r629, 31;
	xor.b32  	%r636, %r635, %r629;
	xor.b32  	%r637, %r635, %r630;
	cvt.u64.u32 	%rd161, %r636;
	shl.b64 	%rd162, %rd161, 32;
	cvt.u64.u32 	%rd163, %r637;
	or.b64  	%rd164, %rd162, %rd163;
	cvt.rn.f64.s64 	%fd7, %rd164;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f458, %fd8;
	neg.f32 	%f459, %f458;
	setp.lt.s32 	%p42, %r634, 0;
	selp.f32 	%f1008, %f459, %f458, %p42;
$L__BB0_44:                             // %__internal_trig_reduction_kernel.exit.i.i139
	mul.rn.ftz.f32 	%f67, %f1008, %f1008;
	and.b32  	%r639, %r1226, 1;
	setp.eq.b32 	%p43, %r639, 1;
	not.pred 	%p44, %p43;
	selp.f32 	%f68, 0f3F800000, %f1008, %p43;
	mov.f32 	%f464, 0f00000000;
	fma.rn.ftz.f32 	%f69, %f67, %f68, %f464;
	mov.f32 	%f1011, 0fB94D4153;
	mov.f32 	%f1010, 0f3C0885E4;
	mov.f32 	%f1009, 0fBE2AAAA8;
	@%p44 bra 	$L__BB0_46;
// %bb.45:                              // %__internal_fmad.exit1.i.i.i147
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f465, 0fBAB607ED;
	mov.f32 	%f466, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1011, %f466, %f67, %f465;
	mov.f32 	%f1010, 0f3D2AAABB;
	mov.f32 	%f1009, 0fBEFFFFFF;
$L__BB0_46:                             // %__internal_fmad.exit2.i.i.i150
	mov.b32 	%f13, %r458;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f469, %f1011, %f67, %f1010;
	fma.rn.ftz.f32 	%f470, %f469, %f67, %f1009;
	fma.rn.ftz.f32 	%f1012, %f470, %f69, %f68;
	and.b32  	%r640, %r1226, 2;
	setp.eq.s32 	%p45, %r640, 0;
	@%p45 bra 	$L__BB0_48;
// %bb.47:                              // %__internal_fmad.exit5.i.i.i158
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f472, 0fBF800000;
	fma.rn.ftz.f32 	%f1012, %f1012, %f472, %f464;
$L__BB0_48:                             // %__nv_sinf.exit165
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f473, %f13, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1230, %f473;
	cvt.rn.f32.s32 	%f474, %r1230;
	mov.f32 	%f475, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f476, %f474, %f475, %f13;
	mov.f32 	%f477, 0fB3A22168;
	fma.rn.ftz.f32 	%f478, %f474, %f477, %f476;
	mov.f32 	%f479, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1013, %f474, %f479, %f478;
	abs.ftz.f32 	%f78, %f13;
	setp.ltu.f32 	%p46, %f78, 0f47CE4780;
	@%p46 bra 	$L__BB0_56;
// %bb.49:                              // %__nv_isinff.exit.i.i.i177
	setp.neu.f32 	%p47, %f78, 0f7F800000;
	@%p47 bra 	$L__BB0_51;
// %bb.50:                              // %__nv_fmul_rn.exit.i.i.i217
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f482, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1013, %f13, %f482;
	mov.b32 	%r1230, 0;
	bra.uni 	$L__BB0_56;
$L__BB0_51:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r20, %rd118;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r111, %r458, 23;
	and.b32  	%r642, %r111, 224;
	add.s32 	%r643, %r642, -128;
	shl.b32 	%r644, %r458, 8;
	or.b32  	%r648, %r644, -2147483648;
	shr.u32 	%r113, %r643, 5;
	mov.b32 	%r1228, 0;
	mov.b64 	%rd321, 0;
	mov.u64 	%rd166, __cudart_i2opi_f;
	mov.u32 	%r1227, %r20;
$L__BB0_52:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd167, %rd166, %rd321;
	ld.global.nc.u32 	%r647, [%rd167];
	// begin inline asm
	{
	mad.lo.cc.u32   %r645, %r647, %r648, %r1228;
	madc.hi.u32     %r1228, %r647, %r648,  0;
	}
	// end inline asm
	st.local.u32 	[%r1227], %r645;
	add.s32 	%r1227, %r1227, 4;
	add.s64 	%rd321, %rd321, 4;
	setp.ne.s64 	%p48, %rd321, 24;
	@%p48 bra 	$L__BB0_52;
// %bb.53:
	st.local.u32 	[%r20+24], %r1228;
	shl.b32 	%r650, %r113, 2;
	sub.s32 	%r118, %r20, %r650;
	ld.local.u32 	%r119, [%r118+24];
	ld.local.u32 	%r120, [%r118+20];
	and.b32  	%r652, %r458, 260046848;
	setp.eq.s32 	%p49, %r652, 0;
	mov.u32 	%r1229, %r120;
	@%p49 bra 	$L__BB0_55;
// %bb.54:
	ld.local.u32 	%r653, [%r118+16];
	shf.l.wrap.b32 	%r1229, %r653, %r120, %r111;
$L__BB0_55:                             // %__internal_trig_reduction_slowpath.exit.i.i.i183
	shf.l.wrap.b32 	%r654, %r120, %r119, %r111;
	shr.u32 	%r655, %r654, 30;
	shf.l.wrap.b32 	%r656, %r1229, %r654, 2;
	shl.b32 	%r657, %r1229, 2;
	shr.u32 	%r658, %r656, 31;
	add.s32 	%r659, %r658, %r655;
	neg.s32 	%r660, %r659;
	setp.lt.s32 	%p50, %r458, 0;
	selp.b32 	%r1230, %r660, %r659, %p50;
	xor.b32  	%r661, %r656, %r458;
	shr.s32 	%r662, %r656, 31;
	xor.b32  	%r663, %r662, %r656;
	xor.b32  	%r664, %r662, %r657;
	cvt.u64.u32 	%rd168, %r663;
	shl.b64 	%rd169, %rd168, 32;
	cvt.u64.u32 	%rd170, %r664;
	or.b64  	%rd171, %rd169, %rd170;
	cvt.rn.f64.s64 	%fd9, %rd171;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f480, %fd10;
	neg.f32 	%f481, %f480;
	setp.lt.s32 	%p51, %r661, 0;
	selp.f32 	%f1013, %f481, %f480, %p51;
$L__BB0_56:                             // %__internal_trig_reduction_kernel.exit.i.i194
	mul.rn.ftz.f32 	%f82, %f1013, %f1013;
	and.b32  	%r666, %r1230, 1;
	setp.eq.b32 	%p52, %r666, 1;
	not.pred 	%p53, %p52;
	selp.f32 	%f83, 0f3F800000, %f1013, %p52;
	mov.f32 	%f486, 0f00000000;
	fma.rn.ftz.f32 	%f84, %f82, %f83, %f486;
	mov.f32 	%f1016, 0fB94D4153;
	mov.f32 	%f1015, 0f3C0885E4;
	mov.f32 	%f1014, 0fBE2AAAA8;
	@%p53 bra 	$L__BB0_58;
// %bb.57:                              // %__internal_fmad.exit1.i.i.i202
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f487, 0fBAB607ED;
	mov.f32 	%f488, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1016, %f488, %f82, %f487;
	mov.f32 	%f1015, 0f3D2AAABB;
	mov.f32 	%f1014, 0fBEFFFFFF;
$L__BB0_58:                             // %__internal_fmad.exit2.i.i.i205
	mov.b32 	%f14, %r460;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f491, %f1016, %f82, %f1015;
	fma.rn.ftz.f32 	%f492, %f491, %f82, %f1014;
	fma.rn.ftz.f32 	%f1017, %f492, %f84, %f83;
	and.b32  	%r667, %r1230, 2;
	setp.eq.s32 	%p54, %r667, 0;
	@%p54 bra 	$L__BB0_60;
// %bb.59:                              // %__internal_fmad.exit5.i.i.i213
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f494, 0fBF800000;
	fma.rn.ftz.f32 	%f1017, %f1017, %f494, %f486;
$L__BB0_60:                             // %__nv_sinf.exit220
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f495, %f14, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1234, %f495;
	cvt.rn.f32.s32 	%f496, %r1234;
	mov.f32 	%f497, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f498, %f496, %f497, %f14;
	mov.f32 	%f499, 0fB3A22168;
	fma.rn.ftz.f32 	%f500, %f496, %f499, %f498;
	mov.f32 	%f501, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1018, %f496, %f501, %f500;
	abs.ftz.f32 	%f93, %f14;
	setp.ltu.f32 	%p55, %f93, 0f47CE4780;
	@%p55 bra 	$L__BB0_68;
// %bb.61:                              // %__nv_isinff.exit.i.i.i232
	setp.neu.f32 	%p56, %f93, 0f7F800000;
	@%p56 bra 	$L__BB0_63;
// %bb.62:                              // %__nv_fmul_rn.exit.i.i.i272
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f504, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1018, %f14, %f504;
	mov.b32 	%r1234, 0;
	bra.uni 	$L__BB0_68;
$L__BB0_63:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r19, %rd116;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r126, %r460, 23;
	and.b32  	%r669, %r126, 224;
	add.s32 	%r670, %r669, -128;
	shl.b32 	%r671, %r460, 8;
	or.b32  	%r675, %r671, -2147483648;
	shr.u32 	%r128, %r670, 5;
	mov.b32 	%r1232, 0;
	mov.b64 	%rd322, 0;
	mov.u64 	%rd173, __cudart_i2opi_f;
	mov.u32 	%r1231, %r19;
$L__BB0_64:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd174, %rd173, %rd322;
	ld.global.nc.u32 	%r674, [%rd174];
	// begin inline asm
	{
	mad.lo.cc.u32   %r672, %r674, %r675, %r1232;
	madc.hi.u32     %r1232, %r674, %r675,  0;
	}
	// end inline asm
	st.local.u32 	[%r1231], %r672;
	add.s32 	%r1231, %r1231, 4;
	add.s64 	%rd322, %rd322, 4;
	setp.ne.s64 	%p57, %rd322, 24;
	@%p57 bra 	$L__BB0_64;
// %bb.65:
	st.local.u32 	[%r19+24], %r1232;
	shl.b32 	%r677, %r128, 2;
	sub.s32 	%r133, %r19, %r677;
	ld.local.u32 	%r134, [%r133+24];
	ld.local.u32 	%r135, [%r133+20];
	and.b32  	%r679, %r460, 260046848;
	setp.eq.s32 	%p58, %r679, 0;
	mov.u32 	%r1233, %r135;
	@%p58 bra 	$L__BB0_67;
// %bb.66:
	ld.local.u32 	%r680, [%r133+16];
	shf.l.wrap.b32 	%r1233, %r680, %r135, %r126;
$L__BB0_67:                             // %__internal_trig_reduction_slowpath.exit.i.i.i238
	shf.l.wrap.b32 	%r681, %r135, %r134, %r126;
	shr.u32 	%r682, %r681, 30;
	shf.l.wrap.b32 	%r683, %r1233, %r681, 2;
	shl.b32 	%r684, %r1233, 2;
	shr.u32 	%r685, %r683, 31;
	add.s32 	%r686, %r685, %r682;
	neg.s32 	%r687, %r686;
	setp.lt.s32 	%p59, %r460, 0;
	selp.b32 	%r1234, %r687, %r686, %p59;
	xor.b32  	%r688, %r683, %r460;
	shr.s32 	%r689, %r683, 31;
	xor.b32  	%r690, %r689, %r683;
	xor.b32  	%r691, %r689, %r684;
	cvt.u64.u32 	%rd175, %r690;
	shl.b64 	%rd176, %rd175, 32;
	cvt.u64.u32 	%rd177, %r691;
	or.b64  	%rd178, %rd176, %rd177;
	cvt.rn.f64.s64 	%fd11, %rd178;
	mul.f64 	%fd12, %fd11, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f502, %fd12;
	neg.f32 	%f503, %f502;
	setp.lt.s32 	%p60, %r688, 0;
	selp.f32 	%f1018, %f503, %f502, %p60;
$L__BB0_68:                             // %__internal_trig_reduction_kernel.exit.i.i249
	mul.rn.ftz.f32 	%f97, %f1018, %f1018;
	and.b32  	%r693, %r1234, 1;
	setp.eq.b32 	%p61, %r693, 1;
	not.pred 	%p62, %p61;
	selp.f32 	%f98, 0f3F800000, %f1018, %p61;
	mov.f32 	%f508, 0f00000000;
	fma.rn.ftz.f32 	%f99, %f97, %f98, %f508;
	mov.f32 	%f1021, 0fB94D4153;
	mov.f32 	%f1020, 0f3C0885E4;
	mov.f32 	%f1019, 0fBE2AAAA8;
	@%p62 bra 	$L__BB0_70;
// %bb.69:                              // %__internal_fmad.exit1.i.i.i257
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f509, 0fBAB607ED;
	mov.f32 	%f510, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1021, %f510, %f97, %f509;
	mov.f32 	%f1020, 0f3D2AAABB;
	mov.f32 	%f1019, 0fBEFFFFFF;
$L__BB0_70:                             // %__internal_fmad.exit2.i.i.i260
	mov.b32 	%f15, %r462;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f513, %f1021, %f97, %f1020;
	fma.rn.ftz.f32 	%f514, %f513, %f97, %f1019;
	fma.rn.ftz.f32 	%f1022, %f514, %f99, %f98;
	and.b32  	%r694, %r1234, 2;
	setp.eq.s32 	%p63, %r694, 0;
	@%p63 bra 	$L__BB0_72;
// %bb.71:                              // %__internal_fmad.exit5.i.i.i268
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f516, 0fBF800000;
	fma.rn.ftz.f32 	%f1022, %f1022, %f516, %f508;
$L__BB0_72:                             // %__nv_sinf.exit275
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f517, %f15, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1238, %f517;
	cvt.rn.f32.s32 	%f518, %r1238;
	mov.f32 	%f519, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f520, %f518, %f519, %f15;
	mov.f32 	%f521, 0fB3A22168;
	fma.rn.ftz.f32 	%f522, %f518, %f521, %f520;
	mov.f32 	%f523, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1023, %f518, %f523, %f522;
	abs.ftz.f32 	%f108, %f15;
	setp.ltu.f32 	%p64, %f108, 0f47CE4780;
	@%p64 bra 	$L__BB0_80;
// %bb.73:                              // %__nv_isinff.exit.i.i.i287
	setp.neu.f32 	%p65, %f108, 0f7F800000;
	@%p65 bra 	$L__BB0_75;
// %bb.74:                              // %__nv_fmul_rn.exit.i.i.i327
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f526, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1023, %f15, %f526;
	mov.b32 	%r1238, 0;
	bra.uni 	$L__BB0_80;
$L__BB0_75:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r18, %rd114;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r141, %r462, 23;
	and.b32  	%r696, %r141, 224;
	add.s32 	%r697, %r696, -128;
	shl.b32 	%r698, %r462, 8;
	or.b32  	%r702, %r698, -2147483648;
	shr.u32 	%r143, %r697, 5;
	mov.b32 	%r1236, 0;
	mov.b64 	%rd323, 0;
	mov.u64 	%rd180, __cudart_i2opi_f;
	mov.u32 	%r1235, %r18;
$L__BB0_76:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd181, %rd180, %rd323;
	ld.global.nc.u32 	%r701, [%rd181];
	// begin inline asm
	{
	mad.lo.cc.u32   %r699, %r701, %r702, %r1236;
	madc.hi.u32     %r1236, %r701, %r702,  0;
	}
	// end inline asm
	st.local.u32 	[%r1235], %r699;
	add.s32 	%r1235, %r1235, 4;
	add.s64 	%rd323, %rd323, 4;
	setp.ne.s64 	%p66, %rd323, 24;
	@%p66 bra 	$L__BB0_76;
// %bb.77:
	st.local.u32 	[%r18+24], %r1236;
	shl.b32 	%r704, %r143, 2;
	sub.s32 	%r148, %r18, %r704;
	ld.local.u32 	%r149, [%r148+24];
	ld.local.u32 	%r150, [%r148+20];
	and.b32  	%r706, %r462, 260046848;
	setp.eq.s32 	%p67, %r706, 0;
	mov.u32 	%r1237, %r150;
	@%p67 bra 	$L__BB0_79;
// %bb.78:
	ld.local.u32 	%r707, [%r148+16];
	shf.l.wrap.b32 	%r1237, %r707, %r150, %r141;
$L__BB0_79:                             // %__internal_trig_reduction_slowpath.exit.i.i.i293
	shf.l.wrap.b32 	%r708, %r150, %r149, %r141;
	shr.u32 	%r709, %r708, 30;
	shf.l.wrap.b32 	%r710, %r1237, %r708, 2;
	shl.b32 	%r711, %r1237, 2;
	shr.u32 	%r712, %r710, 31;
	add.s32 	%r713, %r712, %r709;
	neg.s32 	%r714, %r713;
	setp.lt.s32 	%p68, %r462, 0;
	selp.b32 	%r1238, %r714, %r713, %p68;
	xor.b32  	%r715, %r710, %r462;
	shr.s32 	%r716, %r710, 31;
	xor.b32  	%r717, %r716, %r710;
	xor.b32  	%r718, %r716, %r711;
	cvt.u64.u32 	%rd182, %r717;
	shl.b64 	%rd183, %rd182, 32;
	cvt.u64.u32 	%rd184, %r718;
	or.b64  	%rd185, %rd183, %rd184;
	cvt.rn.f64.s64 	%fd13, %rd185;
	mul.f64 	%fd14, %fd13, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f524, %fd14;
	neg.f32 	%f525, %f524;
	setp.lt.s32 	%p69, %r715, 0;
	selp.f32 	%f1023, %f525, %f524, %p69;
$L__BB0_80:                             // %__internal_trig_reduction_kernel.exit.i.i304
	mul.rn.ftz.f32 	%f112, %f1023, %f1023;
	and.b32  	%r720, %r1238, 1;
	setp.eq.b32 	%p70, %r720, 1;
	not.pred 	%p71, %p70;
	selp.f32 	%f113, 0f3F800000, %f1023, %p70;
	mov.f32 	%f530, 0f00000000;
	fma.rn.ftz.f32 	%f114, %f112, %f113, %f530;
	mov.f32 	%f1026, 0fB94D4153;
	mov.f32 	%f1025, 0f3C0885E4;
	mov.f32 	%f1024, 0fBE2AAAA8;
	@%p71 bra 	$L__BB0_82;
// %bb.81:                              // %__internal_fmad.exit1.i.i.i312
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f531, 0fBAB607ED;
	mov.f32 	%f532, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1026, %f532, %f112, %f531;
	mov.f32 	%f1025, 0f3D2AAABB;
	mov.f32 	%f1024, 0fBEFFFFFF;
$L__BB0_82:                             // %__internal_fmad.exit2.i.i.i315
	mov.b32 	%f16, %r464;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f535, %f1026, %f112, %f1025;
	fma.rn.ftz.f32 	%f536, %f535, %f112, %f1024;
	fma.rn.ftz.f32 	%f1027, %f536, %f114, %f113;
	and.b32  	%r721, %r1238, 2;
	setp.eq.s32 	%p72, %r721, 0;
	@%p72 bra 	$L__BB0_84;
// %bb.83:                              // %__internal_fmad.exit5.i.i.i323
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f538, 0fBF800000;
	fma.rn.ftz.f32 	%f1027, %f1027, %f538, %f530;
$L__BB0_84:                             // %__nv_sinf.exit330
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.f32 	%f539, %f16, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1242, %f539;
	cvt.rn.f32.s32 	%f540, %r1242;
	mov.f32 	%f541, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f542, %f540, %f541, %f16;
	mov.f32 	%f543, 0fB3A22168;
	fma.rn.ftz.f32 	%f544, %f540, %f543, %f542;
	mov.f32 	%f545, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1028, %f540, %f545, %f544;
	abs.ftz.f32 	%f123, %f16;
	setp.ltu.f32 	%p73, %f123, 0f47CE4780;
	@%p73 bra 	$L__BB0_92;
// %bb.85:                              // %__nv_isinff.exit.i.i.i342
	setp.neu.f32 	%p74, %f123, 0f7F800000;
	@%p74 bra 	$L__BB0_87;
// %bb.86:                              // %__nv_fmul_rn.exit.i.i.i382
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f548, 0f00000000;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	mul.rn.ftz.f32 	%f1028, %f16, %f548;
	mov.b32 	%r1242, 0;
	bra.uni 	$L__BB0_92;
$L__BB0_87:
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	cvt.u32.u64 	%r17, %rd112;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	shr.u32 	%r156, %r464, 23;
	and.b32  	%r723, %r156, 224;
	add.s32 	%r724, %r723, -128;
	shl.b32 	%r725, %r464, 8;
	or.b32  	%r729, %r725, -2147483648;
	shr.u32 	%r158, %r724, 5;
	mov.b32 	%r1240, 0;
	mov.b64 	%rd324, 0;
	mov.u64 	%rd187, __cudart_i2opi_f;
	mov.u32 	%r1239, %r17;
$L__BB0_88:                             // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd188, %rd187, %rd324;
	ld.global.nc.u32 	%r728, [%rd188];
	// begin inline asm
	{
	mad.lo.cc.u32   %r726, %r728, %r729, %r1240;
	madc.hi.u32     %r1240, %r728, %r729,  0;
	}
	// end inline asm
	st.local.u32 	[%r1239], %r726;
	add.s32 	%r1239, %r1239, 4;
	add.s64 	%rd324, %rd324, 4;
	setp.ne.s64 	%p75, %rd324, 24;
	@%p75 bra 	$L__BB0_88;
// %bb.89:
	st.local.u32 	[%r17+24], %r1240;
	shl.b32 	%r731, %r158, 2;
	sub.s32 	%r163, %r17, %r731;
	ld.local.u32 	%r164, [%r163+24];
	ld.local.u32 	%r165, [%r163+20];
	and.b32  	%r733, %r464, 260046848;
	setp.eq.s32 	%p76, %r733, 0;
	mov.u32 	%r1241, %r165;
	@%p76 bra 	$L__BB0_91;
// %bb.90:
	ld.local.u32 	%r734, [%r163+16];
	shf.l.wrap.b32 	%r1241, %r734, %r165, %r156;
$L__BB0_91:                             // %__internal_trig_reduction_slowpath.exit.i.i.i348
	shf.l.wrap.b32 	%r735, %r165, %r164, %r156;
	shr.u32 	%r736, %r735, 30;
	shf.l.wrap.b32 	%r737, %r1241, %r735, 2;
	shl.b32 	%r738, %r1241, 2;
	shr.u32 	%r739, %r737, 31;
	add.s32 	%r740, %r739, %r736;
	neg.s32 	%r741, %r740;
	setp.lt.s32 	%p77, %r464, 0;
	selp.b32 	%r1242, %r741, %r740, %p77;
	xor.b32  	%r742, %r737, %r464;
	shr.s32 	%r743, %r737, 31;
	xor.b32  	%r744, %r743, %r737;
	xor.b32  	%r745, %r743, %r738;
	cvt.u64.u32 	%rd189, %r744;
	shl.b64 	%rd190, %rd189, 32;
	cvt.u64.u32 	%rd191, %r745;
	or.b64  	%rd192, %rd190, %rd191;
	cvt.rn.f64.s64 	%fd15, %rd192;
	mul.f64 	%fd16, %fd15, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f546, %fd16;
	neg.f32 	%f547, %f546;
	setp.lt.s32 	%p78, %r742, 0;
	selp.f32 	%f1028, %f547, %f546, %p78;
$L__BB0_92:                             // %__internal_trig_reduction_kernel.exit.i.i359
	mul.rn.ftz.f32 	%f127, %f1028, %f1028;
	and.b32  	%r747, %r1242, 1;
	setp.eq.b32 	%p79, %r747, 1;
	not.pred 	%p80, %p79;
	selp.f32 	%f128, 0f3F800000, %f1028, %p79;
	mov.f32 	%f552, 0f00000000;
	fma.rn.ftz.f32 	%f129, %f127, %f128, %f552;
	mov.f32 	%f1031, 0fB94D4153;
	mov.f32 	%f1030, 0f3C0885E4;
	mov.f32 	%f1029, 0fBE2AAAA8;
	@%p80 bra 	$L__BB0_94;
// %bb.93:                              // %__internal_fmad.exit1.i.i.i367
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f553, 0fBAB607ED;
	mov.f32 	%f554, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1031, %f554, %f127, %f553;
	mov.f32 	%f1030, 0f3D2AAABB;
	mov.f32 	%f1029, 0fBEFFFFFF;
$L__BB0_94:                             // %__internal_fmad.exit2.i.i.i370
	cvt.s64.s32 	%rd1, %r472;
	.loc	1 32 23                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:32:23
	fma.rn.ftz.f32 	%f557, %f1031, %f127, %f1030;
	fma.rn.ftz.f32 	%f558, %f557, %f127, %f1029;
	fma.rn.ftz.f32 	%f1032, %f558, %f129, %f128;
	and.b32  	%r748, %r1242, 2;
	setp.eq.s32 	%p81, %r748, 0;
	@%p81 bra 	$L__BB0_96;
// %bb.95:                              // %__internal_fmad.exit5.i.i.i378
	.loc	1 0 23                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:23
	mov.f32 	%f560, 0fBF800000;
	fma.rn.ftz.f32 	%f1032, %f1032, %f560, %f552;
$L__BB0_96:                             // %__nv_sinf.exit385
	cvt.u32.u64 	%r773, %rd1;
	.loc	1 42 19                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:42:19
	setp.lt.s32 	%p82, %r25, 64;
	.loc	1 43 36                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:36
	add.s32 	%r774, %r773, 64;
	.loc	1 43 31                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:31
	mul.wide.s32 	%rd202, %r774, 2;
	add.s64 	%rd193, %rd58, %rd202;
	mov.b32 	%r753, 0;
	.loc	1 43 41                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:41
	// begin inline asm
	mov.u32 %r749, %r753;
	mov.u32 %r750, %r753;
	mov.u32 %r751, %r753;
	mov.u32 %r752, %r753;
	@%p82 ld.global.v4.b32 { %r749, %r750, %r751, %r752 }, [ %rd193 + 0 ];
	// end inline asm
	.loc	1 44 54                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:44:54
	// begin inline asm
	mov.u32 %r757, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r757 }, [ %rd61 + 0 ];
	// end inline asm
	mov.b32 	%f137, %r757;
	// begin inline asm
	mov.u32 %r759, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r759 }, [ %rd62 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r761, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r761 }, [ %rd63 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r763, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r763 }, [ %rd64 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r765, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r765 }, [ %rd65 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r767, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r767 }, [ %rd66 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r769, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r769 }, [ %rd67 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r771, %r753;
	@%p82 ld.global.L1::evict_last.b32 { %r771 }, [ %rd68 + 0 ];
	// end inline asm
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f561, %f137, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1246, %f561;
	cvt.rn.f32.s32 	%f562, %r1246;
	mov.f32 	%f563, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f564, %f562, %f563, %f137;
	mov.f32 	%f565, 0fB3A22168;
	fma.rn.ftz.f32 	%f566, %f562, %f565, %f564;
	mov.f32 	%f567, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1033, %f562, %f567, %f566;
	abs.ftz.f32 	%f146, %f137;
	setp.ltu.f32 	%p91, %f146, 0f47CE4780;
	@%p91 bra 	$L__BB0_104;
// %bb.97:                              // %__nv_isinff.exit.i.i.i397
	setp.neu.f32 	%p92, %f146, 0f7F800000;
	@%p92 bra 	$L__BB0_99;
// %bb.98:                              // %__nv_fmul_rn.exit.i.i.i437
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f570, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1033, %f137, %f570;
	mov.b32 	%r1246, 0;
	bra.uni 	$L__BB0_104;
$L__BB0_99:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r16, %rd110;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r183, %r757, 23;
	and.b32  	%r776, %r183, 224;
	add.s32 	%r777, %r776, -128;
	shl.b32 	%r778, %r757, 8;
	or.b32  	%r782, %r778, -2147483648;
	shr.u32 	%r185, %r777, 5;
	mov.b32 	%r1244, 0;
	mov.b64 	%rd325, 0;
	mov.u64 	%rd204, __cudart_i2opi_f;
	mov.u32 	%r1243, %r16;
$L__BB0_100:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd205, %rd204, %rd325;
	ld.global.nc.u32 	%r781, [%rd205];
	// begin inline asm
	{
	mad.lo.cc.u32   %r779, %r781, %r782, %r1244;
	madc.hi.u32     %r1244, %r781, %r782,  0;
	}
	// end inline asm
	st.local.u32 	[%r1243], %r779;
	add.s32 	%r1243, %r1243, 4;
	add.s64 	%rd325, %rd325, 4;
	setp.ne.s64 	%p93, %rd325, 24;
	@%p93 bra 	$L__BB0_100;
// %bb.101:
	st.local.u32 	[%r16+24], %r1244;
	shl.b32 	%r784, %r185, 2;
	sub.s32 	%r190, %r16, %r784;
	ld.local.u32 	%r191, [%r190+24];
	ld.local.u32 	%r192, [%r190+20];
	and.b32  	%r786, %r757, 260046848;
	setp.eq.s32 	%p94, %r786, 0;
	mov.u32 	%r1245, %r192;
	@%p94 bra 	$L__BB0_103;
// %bb.102:
	ld.local.u32 	%r787, [%r190+16];
	shf.l.wrap.b32 	%r1245, %r787, %r192, %r183;
$L__BB0_103:                            // %__internal_trig_reduction_slowpath.exit.i.i.i403
	shf.l.wrap.b32 	%r788, %r192, %r191, %r183;
	shr.u32 	%r789, %r788, 30;
	shf.l.wrap.b32 	%r790, %r1245, %r788, 2;
	shl.b32 	%r791, %r1245, 2;
	shr.u32 	%r792, %r790, 31;
	add.s32 	%r793, %r792, %r789;
	neg.s32 	%r794, %r793;
	setp.lt.s32 	%p95, %r757, 0;
	selp.b32 	%r1246, %r794, %r793, %p95;
	xor.b32  	%r795, %r790, %r757;
	shr.s32 	%r796, %r790, 31;
	xor.b32  	%r797, %r796, %r790;
	xor.b32  	%r798, %r796, %r791;
	cvt.u64.u32 	%rd206, %r797;
	shl.b64 	%rd207, %rd206, 32;
	cvt.u64.u32 	%rd208, %r798;
	or.b64  	%rd209, %rd207, %rd208;
	cvt.rn.f64.s64 	%fd17, %rd209;
	mul.f64 	%fd18, %fd17, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f568, %fd18;
	neg.f32 	%f569, %f568;
	setp.lt.s32 	%p96, %r795, 0;
	selp.f32 	%f1033, %f569, %f568, %p96;
$L__BB0_104:                            // %__internal_trig_reduction_kernel.exit.i.i414
	mul.rn.ftz.f32 	%f150, %f1033, %f1033;
	and.b32  	%r800, %r1246, 1;
	setp.eq.b32 	%p97, %r800, 1;
	not.pred 	%p98, %p97;
	selp.f32 	%f151, 0f3F800000, %f1033, %p97;
	mov.f32 	%f574, 0f00000000;
	fma.rn.ftz.f32 	%f152, %f150, %f151, %f574;
	mov.f32 	%f1036, 0fB94D4153;
	mov.f32 	%f1035, 0f3C0885E4;
	mov.f32 	%f1034, 0fBE2AAAA8;
	@%p98 bra 	$L__BB0_106;
// %bb.105:                             // %__internal_fmad.exit1.i.i.i422
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f575, 0fBAB607ED;
	mov.f32 	%f576, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1036, %f576, %f150, %f575;
	mov.f32 	%f1035, 0f3D2AAABB;
	mov.f32 	%f1034, 0fBEFFFFFF;
$L__BB0_106:                            // %__internal_fmad.exit2.i.i.i425
	mov.b32 	%f138, %r759;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f579, %f1036, %f150, %f1035;
	fma.rn.ftz.f32 	%f580, %f579, %f150, %f1034;
	fma.rn.ftz.f32 	%f1037, %f580, %f152, %f151;
	and.b32  	%r801, %r1246, 2;
	setp.eq.s32 	%p99, %r801, 0;
	@%p99 bra 	$L__BB0_108;
// %bb.107:                             // %__internal_fmad.exit5.i.i.i433
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f582, 0fBF800000;
	fma.rn.ftz.f32 	%f1037, %f1037, %f582, %f574;
$L__BB0_108:                            // %__nv_sinf.exit440
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f583, %f138, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1250, %f583;
	cvt.rn.f32.s32 	%f584, %r1250;
	mov.f32 	%f585, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f586, %f584, %f585, %f138;
	mov.f32 	%f587, 0fB3A22168;
	fma.rn.ftz.f32 	%f588, %f584, %f587, %f586;
	mov.f32 	%f589, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1038, %f584, %f589, %f588;
	abs.ftz.f32 	%f161, %f138;
	setp.ltu.f32 	%p100, %f161, 0f47CE4780;
	@%p100 bra 	$L__BB0_116;
// %bb.109:                             // %__nv_isinff.exit.i.i.i452
	setp.neu.f32 	%p101, %f161, 0f7F800000;
	@%p101 bra 	$L__BB0_111;
// %bb.110:                             // %__nv_fmul_rn.exit.i.i.i492
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f592, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1038, %f138, %f592;
	mov.b32 	%r1250, 0;
	bra.uni 	$L__BB0_116;
$L__BB0_111:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r15, %rd108;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r198, %r759, 23;
	and.b32  	%r803, %r198, 224;
	add.s32 	%r804, %r803, -128;
	shl.b32 	%r805, %r759, 8;
	or.b32  	%r809, %r805, -2147483648;
	shr.u32 	%r200, %r804, 5;
	mov.b32 	%r1248, 0;
	mov.b64 	%rd326, 0;
	mov.u64 	%rd211, __cudart_i2opi_f;
	mov.u32 	%r1247, %r15;
$L__BB0_112:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd212, %rd211, %rd326;
	ld.global.nc.u32 	%r808, [%rd212];
	// begin inline asm
	{
	mad.lo.cc.u32   %r806, %r808, %r809, %r1248;
	madc.hi.u32     %r1248, %r808, %r809,  0;
	}
	// end inline asm
	st.local.u32 	[%r1247], %r806;
	add.s32 	%r1247, %r1247, 4;
	add.s64 	%rd326, %rd326, 4;
	setp.ne.s64 	%p102, %rd326, 24;
	@%p102 bra 	$L__BB0_112;
// %bb.113:
	st.local.u32 	[%r15+24], %r1248;
	shl.b32 	%r811, %r200, 2;
	sub.s32 	%r205, %r15, %r811;
	ld.local.u32 	%r206, [%r205+24];
	ld.local.u32 	%r207, [%r205+20];
	and.b32  	%r813, %r759, 260046848;
	setp.eq.s32 	%p103, %r813, 0;
	mov.u32 	%r1249, %r207;
	@%p103 bra 	$L__BB0_115;
// %bb.114:
	ld.local.u32 	%r814, [%r205+16];
	shf.l.wrap.b32 	%r1249, %r814, %r207, %r198;
$L__BB0_115:                            // %__internal_trig_reduction_slowpath.exit.i.i.i458
	shf.l.wrap.b32 	%r815, %r207, %r206, %r198;
	shr.u32 	%r816, %r815, 30;
	shf.l.wrap.b32 	%r817, %r1249, %r815, 2;
	shl.b32 	%r818, %r1249, 2;
	shr.u32 	%r819, %r817, 31;
	add.s32 	%r820, %r819, %r816;
	neg.s32 	%r821, %r820;
	setp.lt.s32 	%p104, %r759, 0;
	selp.b32 	%r1250, %r821, %r820, %p104;
	xor.b32  	%r822, %r817, %r759;
	shr.s32 	%r823, %r817, 31;
	xor.b32  	%r824, %r823, %r817;
	xor.b32  	%r825, %r823, %r818;
	cvt.u64.u32 	%rd213, %r824;
	shl.b64 	%rd214, %rd213, 32;
	cvt.u64.u32 	%rd215, %r825;
	or.b64  	%rd216, %rd214, %rd215;
	cvt.rn.f64.s64 	%fd19, %rd216;
	mul.f64 	%fd20, %fd19, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f590, %fd20;
	neg.f32 	%f591, %f590;
	setp.lt.s32 	%p105, %r822, 0;
	selp.f32 	%f1038, %f591, %f590, %p105;
$L__BB0_116:                            // %__internal_trig_reduction_kernel.exit.i.i469
	mul.rn.ftz.f32 	%f165, %f1038, %f1038;
	and.b32  	%r827, %r1250, 1;
	setp.eq.b32 	%p106, %r827, 1;
	not.pred 	%p107, %p106;
	selp.f32 	%f166, 0f3F800000, %f1038, %p106;
	mov.f32 	%f596, 0f00000000;
	fma.rn.ftz.f32 	%f167, %f165, %f166, %f596;
	mov.f32 	%f1041, 0fB94D4153;
	mov.f32 	%f1040, 0f3C0885E4;
	mov.f32 	%f1039, 0fBE2AAAA8;
	@%p107 bra 	$L__BB0_118;
// %bb.117:                             // %__internal_fmad.exit1.i.i.i477
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f597, 0fBAB607ED;
	mov.f32 	%f598, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1041, %f598, %f165, %f597;
	mov.f32 	%f1040, 0f3D2AAABB;
	mov.f32 	%f1039, 0fBEFFFFFF;
$L__BB0_118:                            // %__internal_fmad.exit2.i.i.i480
	mov.b32 	%f139, %r761;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f601, %f1041, %f165, %f1040;
	fma.rn.ftz.f32 	%f602, %f601, %f165, %f1039;
	fma.rn.ftz.f32 	%f1042, %f602, %f167, %f166;
	and.b32  	%r828, %r1250, 2;
	setp.eq.s32 	%p108, %r828, 0;
	@%p108 bra 	$L__BB0_120;
// %bb.119:                             // %__internal_fmad.exit5.i.i.i488
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f604, 0fBF800000;
	fma.rn.ftz.f32 	%f1042, %f1042, %f604, %f596;
$L__BB0_120:                            // %__nv_sinf.exit495
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f605, %f139, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1254, %f605;
	cvt.rn.f32.s32 	%f606, %r1254;
	mov.f32 	%f607, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f608, %f606, %f607, %f139;
	mov.f32 	%f609, 0fB3A22168;
	fma.rn.ftz.f32 	%f610, %f606, %f609, %f608;
	mov.f32 	%f611, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1043, %f606, %f611, %f610;
	abs.ftz.f32 	%f176, %f139;
	setp.ltu.f32 	%p109, %f176, 0f47CE4780;
	@%p109 bra 	$L__BB0_128;
// %bb.121:                             // %__nv_isinff.exit.i.i.i507
	setp.neu.f32 	%p110, %f176, 0f7F800000;
	@%p110 bra 	$L__BB0_123;
// %bb.122:                             // %__nv_fmul_rn.exit.i.i.i547
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f614, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1043, %f139, %f614;
	mov.b32 	%r1254, 0;
	bra.uni 	$L__BB0_128;
$L__BB0_123:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r14, %rd106;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r213, %r761, 23;
	and.b32  	%r830, %r213, 224;
	add.s32 	%r831, %r830, -128;
	shl.b32 	%r832, %r761, 8;
	or.b32  	%r836, %r832, -2147483648;
	shr.u32 	%r215, %r831, 5;
	mov.b32 	%r1252, 0;
	mov.b64 	%rd327, 0;
	mov.u64 	%rd218, __cudart_i2opi_f;
	mov.u32 	%r1251, %r14;
$L__BB0_124:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd219, %rd218, %rd327;
	ld.global.nc.u32 	%r835, [%rd219];
	// begin inline asm
	{
	mad.lo.cc.u32   %r833, %r835, %r836, %r1252;
	madc.hi.u32     %r1252, %r835, %r836,  0;
	}
	// end inline asm
	st.local.u32 	[%r1251], %r833;
	add.s32 	%r1251, %r1251, 4;
	add.s64 	%rd327, %rd327, 4;
	setp.ne.s64 	%p111, %rd327, 24;
	@%p111 bra 	$L__BB0_124;
// %bb.125:
	st.local.u32 	[%r14+24], %r1252;
	shl.b32 	%r838, %r215, 2;
	sub.s32 	%r220, %r14, %r838;
	ld.local.u32 	%r221, [%r220+24];
	ld.local.u32 	%r222, [%r220+20];
	and.b32  	%r840, %r761, 260046848;
	setp.eq.s32 	%p112, %r840, 0;
	mov.u32 	%r1253, %r222;
	@%p112 bra 	$L__BB0_127;
// %bb.126:
	ld.local.u32 	%r841, [%r220+16];
	shf.l.wrap.b32 	%r1253, %r841, %r222, %r213;
$L__BB0_127:                            // %__internal_trig_reduction_slowpath.exit.i.i.i513
	shf.l.wrap.b32 	%r842, %r222, %r221, %r213;
	shr.u32 	%r843, %r842, 30;
	shf.l.wrap.b32 	%r844, %r1253, %r842, 2;
	shl.b32 	%r845, %r1253, 2;
	shr.u32 	%r846, %r844, 31;
	add.s32 	%r847, %r846, %r843;
	neg.s32 	%r848, %r847;
	setp.lt.s32 	%p113, %r761, 0;
	selp.b32 	%r1254, %r848, %r847, %p113;
	xor.b32  	%r849, %r844, %r761;
	shr.s32 	%r850, %r844, 31;
	xor.b32  	%r851, %r850, %r844;
	xor.b32  	%r852, %r850, %r845;
	cvt.u64.u32 	%rd220, %r851;
	shl.b64 	%rd221, %rd220, 32;
	cvt.u64.u32 	%rd222, %r852;
	or.b64  	%rd223, %rd221, %rd222;
	cvt.rn.f64.s64 	%fd21, %rd223;
	mul.f64 	%fd22, %fd21, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f612, %fd22;
	neg.f32 	%f613, %f612;
	setp.lt.s32 	%p114, %r849, 0;
	selp.f32 	%f1043, %f613, %f612, %p114;
$L__BB0_128:                            // %__internal_trig_reduction_kernel.exit.i.i524
	mul.rn.ftz.f32 	%f180, %f1043, %f1043;
	and.b32  	%r854, %r1254, 1;
	setp.eq.b32 	%p115, %r854, 1;
	not.pred 	%p116, %p115;
	selp.f32 	%f181, 0f3F800000, %f1043, %p115;
	mov.f32 	%f618, 0f00000000;
	fma.rn.ftz.f32 	%f182, %f180, %f181, %f618;
	mov.f32 	%f1046, 0fB94D4153;
	mov.f32 	%f1045, 0f3C0885E4;
	mov.f32 	%f1044, 0fBE2AAAA8;
	@%p116 bra 	$L__BB0_130;
// %bb.129:                             // %__internal_fmad.exit1.i.i.i532
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f619, 0fBAB607ED;
	mov.f32 	%f620, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1046, %f620, %f180, %f619;
	mov.f32 	%f1045, 0f3D2AAABB;
	mov.f32 	%f1044, 0fBEFFFFFF;
$L__BB0_130:                            // %__internal_fmad.exit2.i.i.i535
	mov.b32 	%f140, %r763;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f623, %f1046, %f180, %f1045;
	fma.rn.ftz.f32 	%f624, %f623, %f180, %f1044;
	fma.rn.ftz.f32 	%f1047, %f624, %f182, %f181;
	and.b32  	%r855, %r1254, 2;
	setp.eq.s32 	%p117, %r855, 0;
	@%p117 bra 	$L__BB0_132;
// %bb.131:                             // %__internal_fmad.exit5.i.i.i543
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f626, 0fBF800000;
	fma.rn.ftz.f32 	%f1047, %f1047, %f626, %f618;
$L__BB0_132:                            // %__nv_sinf.exit550
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f627, %f140, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1258, %f627;
	cvt.rn.f32.s32 	%f628, %r1258;
	mov.f32 	%f629, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f630, %f628, %f629, %f140;
	mov.f32 	%f631, 0fB3A22168;
	fma.rn.ftz.f32 	%f632, %f628, %f631, %f630;
	mov.f32 	%f633, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1048, %f628, %f633, %f632;
	abs.ftz.f32 	%f191, %f140;
	setp.ltu.f32 	%p118, %f191, 0f47CE4780;
	@%p118 bra 	$L__BB0_140;
// %bb.133:                             // %__nv_isinff.exit.i.i.i562
	setp.neu.f32 	%p119, %f191, 0f7F800000;
	@%p119 bra 	$L__BB0_135;
// %bb.134:                             // %__nv_fmul_rn.exit.i.i.i602
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f636, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1048, %f140, %f636;
	mov.b32 	%r1258, 0;
	bra.uni 	$L__BB0_140;
$L__BB0_135:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r13, %rd104;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r228, %r763, 23;
	and.b32  	%r857, %r228, 224;
	add.s32 	%r858, %r857, -128;
	shl.b32 	%r859, %r763, 8;
	or.b32  	%r863, %r859, -2147483648;
	shr.u32 	%r230, %r858, 5;
	mov.b32 	%r1256, 0;
	mov.b64 	%rd328, 0;
	mov.u64 	%rd225, __cudart_i2opi_f;
	mov.u32 	%r1255, %r13;
$L__BB0_136:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd226, %rd225, %rd328;
	ld.global.nc.u32 	%r862, [%rd226];
	// begin inline asm
	{
	mad.lo.cc.u32   %r860, %r862, %r863, %r1256;
	madc.hi.u32     %r1256, %r862, %r863,  0;
	}
	// end inline asm
	st.local.u32 	[%r1255], %r860;
	add.s32 	%r1255, %r1255, 4;
	add.s64 	%rd328, %rd328, 4;
	setp.ne.s64 	%p120, %rd328, 24;
	@%p120 bra 	$L__BB0_136;
// %bb.137:
	st.local.u32 	[%r13+24], %r1256;
	shl.b32 	%r865, %r230, 2;
	sub.s32 	%r235, %r13, %r865;
	ld.local.u32 	%r236, [%r235+24];
	ld.local.u32 	%r237, [%r235+20];
	and.b32  	%r867, %r763, 260046848;
	setp.eq.s32 	%p121, %r867, 0;
	mov.u32 	%r1257, %r237;
	@%p121 bra 	$L__BB0_139;
// %bb.138:
	ld.local.u32 	%r868, [%r235+16];
	shf.l.wrap.b32 	%r1257, %r868, %r237, %r228;
$L__BB0_139:                            // %__internal_trig_reduction_slowpath.exit.i.i.i568
	shf.l.wrap.b32 	%r869, %r237, %r236, %r228;
	shr.u32 	%r870, %r869, 30;
	shf.l.wrap.b32 	%r871, %r1257, %r869, 2;
	shl.b32 	%r872, %r1257, 2;
	shr.u32 	%r873, %r871, 31;
	add.s32 	%r874, %r873, %r870;
	neg.s32 	%r875, %r874;
	setp.lt.s32 	%p122, %r763, 0;
	selp.b32 	%r1258, %r875, %r874, %p122;
	xor.b32  	%r876, %r871, %r763;
	shr.s32 	%r877, %r871, 31;
	xor.b32  	%r878, %r877, %r871;
	xor.b32  	%r879, %r877, %r872;
	cvt.u64.u32 	%rd227, %r878;
	shl.b64 	%rd228, %rd227, 32;
	cvt.u64.u32 	%rd229, %r879;
	or.b64  	%rd230, %rd228, %rd229;
	cvt.rn.f64.s64 	%fd23, %rd230;
	mul.f64 	%fd24, %fd23, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f634, %fd24;
	neg.f32 	%f635, %f634;
	setp.lt.s32 	%p123, %r876, 0;
	selp.f32 	%f1048, %f635, %f634, %p123;
$L__BB0_140:                            // %__internal_trig_reduction_kernel.exit.i.i579
	mul.rn.ftz.f32 	%f195, %f1048, %f1048;
	and.b32  	%r881, %r1258, 1;
	setp.eq.b32 	%p124, %r881, 1;
	not.pred 	%p125, %p124;
	selp.f32 	%f196, 0f3F800000, %f1048, %p124;
	mov.f32 	%f640, 0f00000000;
	fma.rn.ftz.f32 	%f197, %f195, %f196, %f640;
	mov.f32 	%f1051, 0fB94D4153;
	mov.f32 	%f1050, 0f3C0885E4;
	mov.f32 	%f1049, 0fBE2AAAA8;
	@%p125 bra 	$L__BB0_142;
// %bb.141:                             // %__internal_fmad.exit1.i.i.i587
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f641, 0fBAB607ED;
	mov.f32 	%f642, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1051, %f642, %f195, %f641;
	mov.f32 	%f1050, 0f3D2AAABB;
	mov.f32 	%f1049, 0fBEFFFFFF;
$L__BB0_142:                            // %__internal_fmad.exit2.i.i.i590
	mov.b32 	%f141, %r765;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f645, %f1051, %f195, %f1050;
	fma.rn.ftz.f32 	%f646, %f645, %f195, %f1049;
	fma.rn.ftz.f32 	%f1052, %f646, %f197, %f196;
	and.b32  	%r882, %r1258, 2;
	setp.eq.s32 	%p126, %r882, 0;
	@%p126 bra 	$L__BB0_144;
// %bb.143:                             // %__internal_fmad.exit5.i.i.i598
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f648, 0fBF800000;
	fma.rn.ftz.f32 	%f1052, %f1052, %f648, %f640;
$L__BB0_144:                            // %__nv_sinf.exit605
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f649, %f141, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1262, %f649;
	cvt.rn.f32.s32 	%f650, %r1262;
	mov.f32 	%f651, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f652, %f650, %f651, %f141;
	mov.f32 	%f653, 0fB3A22168;
	fma.rn.ftz.f32 	%f654, %f650, %f653, %f652;
	mov.f32 	%f655, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1053, %f650, %f655, %f654;
	abs.ftz.f32 	%f206, %f141;
	setp.ltu.f32 	%p127, %f206, 0f47CE4780;
	@%p127 bra 	$L__BB0_152;
// %bb.145:                             // %__nv_isinff.exit.i.i.i617
	setp.neu.f32 	%p128, %f206, 0f7F800000;
	@%p128 bra 	$L__BB0_147;
// %bb.146:                             // %__nv_fmul_rn.exit.i.i.i657
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f658, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1053, %f141, %f658;
	mov.b32 	%r1262, 0;
	bra.uni 	$L__BB0_152;
$L__BB0_147:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r12, %rd102;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r243, %r765, 23;
	and.b32  	%r884, %r243, 224;
	add.s32 	%r885, %r884, -128;
	shl.b32 	%r886, %r765, 8;
	or.b32  	%r890, %r886, -2147483648;
	shr.u32 	%r245, %r885, 5;
	mov.b32 	%r1260, 0;
	mov.b64 	%rd329, 0;
	mov.u64 	%rd232, __cudart_i2opi_f;
	mov.u32 	%r1259, %r12;
$L__BB0_148:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd233, %rd232, %rd329;
	ld.global.nc.u32 	%r889, [%rd233];
	// begin inline asm
	{
	mad.lo.cc.u32   %r887, %r889, %r890, %r1260;
	madc.hi.u32     %r1260, %r889, %r890,  0;
	}
	// end inline asm
	st.local.u32 	[%r1259], %r887;
	add.s32 	%r1259, %r1259, 4;
	add.s64 	%rd329, %rd329, 4;
	setp.ne.s64 	%p129, %rd329, 24;
	@%p129 bra 	$L__BB0_148;
// %bb.149:
	st.local.u32 	[%r12+24], %r1260;
	shl.b32 	%r892, %r245, 2;
	sub.s32 	%r250, %r12, %r892;
	ld.local.u32 	%r251, [%r250+24];
	ld.local.u32 	%r252, [%r250+20];
	and.b32  	%r894, %r765, 260046848;
	setp.eq.s32 	%p130, %r894, 0;
	mov.u32 	%r1261, %r252;
	@%p130 bra 	$L__BB0_151;
// %bb.150:
	ld.local.u32 	%r895, [%r250+16];
	shf.l.wrap.b32 	%r1261, %r895, %r252, %r243;
$L__BB0_151:                            // %__internal_trig_reduction_slowpath.exit.i.i.i623
	shf.l.wrap.b32 	%r896, %r252, %r251, %r243;
	shr.u32 	%r897, %r896, 30;
	shf.l.wrap.b32 	%r898, %r1261, %r896, 2;
	shl.b32 	%r899, %r1261, 2;
	shr.u32 	%r900, %r898, 31;
	add.s32 	%r901, %r900, %r897;
	neg.s32 	%r902, %r901;
	setp.lt.s32 	%p131, %r765, 0;
	selp.b32 	%r1262, %r902, %r901, %p131;
	xor.b32  	%r903, %r898, %r765;
	shr.s32 	%r904, %r898, 31;
	xor.b32  	%r905, %r904, %r898;
	xor.b32  	%r906, %r904, %r899;
	cvt.u64.u32 	%rd234, %r905;
	shl.b64 	%rd235, %rd234, 32;
	cvt.u64.u32 	%rd236, %r906;
	or.b64  	%rd237, %rd235, %rd236;
	cvt.rn.f64.s64 	%fd25, %rd237;
	mul.f64 	%fd26, %fd25, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f656, %fd26;
	neg.f32 	%f657, %f656;
	setp.lt.s32 	%p132, %r903, 0;
	selp.f32 	%f1053, %f657, %f656, %p132;
$L__BB0_152:                            // %__internal_trig_reduction_kernel.exit.i.i634
	mul.rn.ftz.f32 	%f210, %f1053, %f1053;
	and.b32  	%r908, %r1262, 1;
	setp.eq.b32 	%p133, %r908, 1;
	not.pred 	%p134, %p133;
	selp.f32 	%f211, 0f3F800000, %f1053, %p133;
	mov.f32 	%f662, 0f00000000;
	fma.rn.ftz.f32 	%f212, %f210, %f211, %f662;
	mov.f32 	%f1056, 0fB94D4153;
	mov.f32 	%f1055, 0f3C0885E4;
	mov.f32 	%f1054, 0fBE2AAAA8;
	@%p134 bra 	$L__BB0_154;
// %bb.153:                             // %__internal_fmad.exit1.i.i.i642
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f663, 0fBAB607ED;
	mov.f32 	%f664, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1056, %f664, %f210, %f663;
	mov.f32 	%f1055, 0f3D2AAABB;
	mov.f32 	%f1054, 0fBEFFFFFF;
$L__BB0_154:                            // %__internal_fmad.exit2.i.i.i645
	mov.b32 	%f142, %r767;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f667, %f1056, %f210, %f1055;
	fma.rn.ftz.f32 	%f668, %f667, %f210, %f1054;
	fma.rn.ftz.f32 	%f1057, %f668, %f212, %f211;
	and.b32  	%r909, %r1262, 2;
	setp.eq.s32 	%p135, %r909, 0;
	@%p135 bra 	$L__BB0_156;
// %bb.155:                             // %__internal_fmad.exit5.i.i.i653
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f670, 0fBF800000;
	fma.rn.ftz.f32 	%f1057, %f1057, %f670, %f662;
$L__BB0_156:                            // %__nv_sinf.exit660
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f671, %f142, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1266, %f671;
	cvt.rn.f32.s32 	%f672, %r1266;
	mov.f32 	%f673, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f674, %f672, %f673, %f142;
	mov.f32 	%f675, 0fB3A22168;
	fma.rn.ftz.f32 	%f676, %f672, %f675, %f674;
	mov.f32 	%f677, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1058, %f672, %f677, %f676;
	abs.ftz.f32 	%f221, %f142;
	setp.ltu.f32 	%p136, %f221, 0f47CE4780;
	@%p136 bra 	$L__BB0_164;
// %bb.157:                             // %__nv_isinff.exit.i.i.i672
	setp.neu.f32 	%p137, %f221, 0f7F800000;
	@%p137 bra 	$L__BB0_159;
// %bb.158:                             // %__nv_fmul_rn.exit.i.i.i712
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f680, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1058, %f142, %f680;
	mov.b32 	%r1266, 0;
	bra.uni 	$L__BB0_164;
$L__BB0_159:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r11, %rd100;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r258, %r767, 23;
	and.b32  	%r911, %r258, 224;
	add.s32 	%r912, %r911, -128;
	shl.b32 	%r913, %r767, 8;
	or.b32  	%r917, %r913, -2147483648;
	shr.u32 	%r260, %r912, 5;
	mov.b32 	%r1264, 0;
	mov.b64 	%rd330, 0;
	mov.u64 	%rd239, __cudart_i2opi_f;
	mov.u32 	%r1263, %r11;
$L__BB0_160:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd240, %rd239, %rd330;
	ld.global.nc.u32 	%r916, [%rd240];
	// begin inline asm
	{
	mad.lo.cc.u32   %r914, %r916, %r917, %r1264;
	madc.hi.u32     %r1264, %r916, %r917,  0;
	}
	// end inline asm
	st.local.u32 	[%r1263], %r914;
	add.s32 	%r1263, %r1263, 4;
	add.s64 	%rd330, %rd330, 4;
	setp.ne.s64 	%p138, %rd330, 24;
	@%p138 bra 	$L__BB0_160;
// %bb.161:
	st.local.u32 	[%r11+24], %r1264;
	shl.b32 	%r919, %r260, 2;
	sub.s32 	%r265, %r11, %r919;
	ld.local.u32 	%r266, [%r265+24];
	ld.local.u32 	%r267, [%r265+20];
	and.b32  	%r921, %r767, 260046848;
	setp.eq.s32 	%p139, %r921, 0;
	mov.u32 	%r1265, %r267;
	@%p139 bra 	$L__BB0_163;
// %bb.162:
	ld.local.u32 	%r922, [%r265+16];
	shf.l.wrap.b32 	%r1265, %r922, %r267, %r258;
$L__BB0_163:                            // %__internal_trig_reduction_slowpath.exit.i.i.i678
	shf.l.wrap.b32 	%r923, %r267, %r266, %r258;
	shr.u32 	%r924, %r923, 30;
	shf.l.wrap.b32 	%r925, %r1265, %r923, 2;
	shl.b32 	%r926, %r1265, 2;
	shr.u32 	%r927, %r925, 31;
	add.s32 	%r928, %r927, %r924;
	neg.s32 	%r929, %r928;
	setp.lt.s32 	%p140, %r767, 0;
	selp.b32 	%r1266, %r929, %r928, %p140;
	xor.b32  	%r930, %r925, %r767;
	shr.s32 	%r931, %r925, 31;
	xor.b32  	%r932, %r931, %r925;
	xor.b32  	%r933, %r931, %r926;
	cvt.u64.u32 	%rd241, %r932;
	shl.b64 	%rd242, %rd241, 32;
	cvt.u64.u32 	%rd243, %r933;
	or.b64  	%rd244, %rd242, %rd243;
	cvt.rn.f64.s64 	%fd27, %rd244;
	mul.f64 	%fd28, %fd27, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f678, %fd28;
	neg.f32 	%f679, %f678;
	setp.lt.s32 	%p141, %r930, 0;
	selp.f32 	%f1058, %f679, %f678, %p141;
$L__BB0_164:                            // %__internal_trig_reduction_kernel.exit.i.i689
	mul.rn.ftz.f32 	%f225, %f1058, %f1058;
	and.b32  	%r935, %r1266, 1;
	setp.eq.b32 	%p142, %r935, 1;
	not.pred 	%p143, %p142;
	selp.f32 	%f226, 0f3F800000, %f1058, %p142;
	mov.f32 	%f684, 0f00000000;
	fma.rn.ftz.f32 	%f227, %f225, %f226, %f684;
	mov.f32 	%f1061, 0fB94D4153;
	mov.f32 	%f1060, 0f3C0885E4;
	mov.f32 	%f1059, 0fBE2AAAA8;
	@%p143 bra 	$L__BB0_166;
// %bb.165:                             // %__internal_fmad.exit1.i.i.i697
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f685, 0fBAB607ED;
	mov.f32 	%f686, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1061, %f686, %f225, %f685;
	mov.f32 	%f1060, 0f3D2AAABB;
	mov.f32 	%f1059, 0fBEFFFFFF;
$L__BB0_166:                            // %__internal_fmad.exit2.i.i.i700
	mov.b32 	%f143, %r769;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f689, %f1061, %f225, %f1060;
	fma.rn.ftz.f32 	%f690, %f689, %f225, %f1059;
	fma.rn.ftz.f32 	%f1062, %f690, %f227, %f226;
	and.b32  	%r936, %r1266, 2;
	setp.eq.s32 	%p144, %r936, 0;
	@%p144 bra 	$L__BB0_168;
// %bb.167:                             // %__internal_fmad.exit5.i.i.i708
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f692, 0fBF800000;
	fma.rn.ftz.f32 	%f1062, %f1062, %f692, %f684;
$L__BB0_168:                            // %__nv_sinf.exit715
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f693, %f143, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1270, %f693;
	cvt.rn.f32.s32 	%f694, %r1270;
	mov.f32 	%f695, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f696, %f694, %f695, %f143;
	mov.f32 	%f697, 0fB3A22168;
	fma.rn.ftz.f32 	%f698, %f694, %f697, %f696;
	mov.f32 	%f699, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1063, %f694, %f699, %f698;
	abs.ftz.f32 	%f236, %f143;
	setp.ltu.f32 	%p145, %f236, 0f47CE4780;
	@%p145 bra 	$L__BB0_176;
// %bb.169:                             // %__nv_isinff.exit.i.i.i727
	setp.neu.f32 	%p146, %f236, 0f7F800000;
	@%p146 bra 	$L__BB0_171;
// %bb.170:                             // %__nv_fmul_rn.exit.i.i.i767
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f702, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1063, %f143, %f702;
	mov.b32 	%r1270, 0;
	bra.uni 	$L__BB0_176;
$L__BB0_171:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r10, %rd98;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r273, %r769, 23;
	and.b32  	%r938, %r273, 224;
	add.s32 	%r939, %r938, -128;
	shl.b32 	%r940, %r769, 8;
	or.b32  	%r944, %r940, -2147483648;
	shr.u32 	%r275, %r939, 5;
	mov.b32 	%r1268, 0;
	mov.b64 	%rd331, 0;
	mov.u64 	%rd246, __cudart_i2opi_f;
	mov.u32 	%r1267, %r10;
$L__BB0_172:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd247, %rd246, %rd331;
	ld.global.nc.u32 	%r943, [%rd247];
	// begin inline asm
	{
	mad.lo.cc.u32   %r941, %r943, %r944, %r1268;
	madc.hi.u32     %r1268, %r943, %r944,  0;
	}
	// end inline asm
	st.local.u32 	[%r1267], %r941;
	add.s32 	%r1267, %r1267, 4;
	add.s64 	%rd331, %rd331, 4;
	setp.ne.s64 	%p147, %rd331, 24;
	@%p147 bra 	$L__BB0_172;
// %bb.173:
	st.local.u32 	[%r10+24], %r1268;
	shl.b32 	%r946, %r275, 2;
	sub.s32 	%r280, %r10, %r946;
	ld.local.u32 	%r281, [%r280+24];
	ld.local.u32 	%r282, [%r280+20];
	and.b32  	%r948, %r769, 260046848;
	setp.eq.s32 	%p148, %r948, 0;
	mov.u32 	%r1269, %r282;
	@%p148 bra 	$L__BB0_175;
// %bb.174:
	ld.local.u32 	%r949, [%r280+16];
	shf.l.wrap.b32 	%r1269, %r949, %r282, %r273;
$L__BB0_175:                            // %__internal_trig_reduction_slowpath.exit.i.i.i733
	shf.l.wrap.b32 	%r950, %r282, %r281, %r273;
	shr.u32 	%r951, %r950, 30;
	shf.l.wrap.b32 	%r952, %r1269, %r950, 2;
	shl.b32 	%r953, %r1269, 2;
	shr.u32 	%r954, %r952, 31;
	add.s32 	%r955, %r954, %r951;
	neg.s32 	%r956, %r955;
	setp.lt.s32 	%p149, %r769, 0;
	selp.b32 	%r1270, %r956, %r955, %p149;
	xor.b32  	%r957, %r952, %r769;
	shr.s32 	%r958, %r952, 31;
	xor.b32  	%r959, %r958, %r952;
	xor.b32  	%r960, %r958, %r953;
	cvt.u64.u32 	%rd248, %r959;
	shl.b64 	%rd249, %rd248, 32;
	cvt.u64.u32 	%rd250, %r960;
	or.b64  	%rd251, %rd249, %rd250;
	cvt.rn.f64.s64 	%fd29, %rd251;
	mul.f64 	%fd30, %fd29, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f700, %fd30;
	neg.f32 	%f701, %f700;
	setp.lt.s32 	%p150, %r957, 0;
	selp.f32 	%f1063, %f701, %f700, %p150;
$L__BB0_176:                            // %__internal_trig_reduction_kernel.exit.i.i744
	mul.rn.ftz.f32 	%f240, %f1063, %f1063;
	and.b32  	%r962, %r1270, 1;
	setp.eq.b32 	%p151, %r962, 1;
	not.pred 	%p152, %p151;
	selp.f32 	%f241, 0f3F800000, %f1063, %p151;
	mov.f32 	%f706, 0f00000000;
	fma.rn.ftz.f32 	%f242, %f240, %f241, %f706;
	mov.f32 	%f1066, 0fB94D4153;
	mov.f32 	%f1065, 0f3C0885E4;
	mov.f32 	%f1064, 0fBE2AAAA8;
	@%p152 bra 	$L__BB0_178;
// %bb.177:                             // %__internal_fmad.exit1.i.i.i752
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f707, 0fBAB607ED;
	mov.f32 	%f708, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1066, %f708, %f240, %f707;
	mov.f32 	%f1065, 0f3D2AAABB;
	mov.f32 	%f1064, 0fBEFFFFFF;
$L__BB0_178:                            // %__internal_fmad.exit2.i.i.i755
	mov.b32 	%f144, %r771;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f711, %f1066, %f240, %f1065;
	fma.rn.ftz.f32 	%f712, %f711, %f240, %f1064;
	fma.rn.ftz.f32 	%f1067, %f712, %f242, %f241;
	and.b32  	%r963, %r1270, 2;
	setp.eq.s32 	%p153, %r963, 0;
	@%p153 bra 	$L__BB0_180;
// %bb.179:                             // %__internal_fmad.exit5.i.i.i763
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f714, 0fBF800000;
	fma.rn.ftz.f32 	%f1067, %f1067, %f714, %f706;
$L__BB0_180:                            // %__nv_sinf.exit770
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.f32 	%f715, %f144, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1274, %f715;
	cvt.rn.f32.s32 	%f716, %r1274;
	mov.f32 	%f717, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f718, %f716, %f717, %f144;
	mov.f32 	%f719, 0fB3A22168;
	fma.rn.ftz.f32 	%f720, %f716, %f719, %f718;
	mov.f32 	%f721, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1068, %f716, %f721, %f720;
	abs.ftz.f32 	%f251, %f144;
	setp.ltu.f32 	%p154, %f251, 0f47CE4780;
	@%p154 bra 	$L__BB0_188;
// %bb.181:                             // %__nv_isinff.exit.i.i.i782
	setp.neu.f32 	%p155, %f251, 0f7F800000;
	@%p155 bra 	$L__BB0_183;
// %bb.182:                             // %__nv_fmul_rn.exit.i.i.i822
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f724, 0f00000000;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	mul.rn.ftz.f32 	%f1068, %f144, %f724;
	mov.b32 	%r1274, 0;
	bra.uni 	$L__BB0_188;
$L__BB0_183:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r9, %rd96;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	shr.u32 	%r288, %r771, 23;
	and.b32  	%r965, %r288, 224;
	add.s32 	%r966, %r965, -128;
	shl.b32 	%r967, %r771, 8;
	or.b32  	%r971, %r967, -2147483648;
	shr.u32 	%r290, %r966, 5;
	mov.b32 	%r1272, 0;
	mov.b64 	%rd332, 0;
	mov.u64 	%rd253, __cudart_i2opi_f;
	mov.u32 	%r1271, %r9;
$L__BB0_184:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd254, %rd253, %rd332;
	ld.global.nc.u32 	%r970, [%rd254];
	// begin inline asm
	{
	mad.lo.cc.u32   %r968, %r970, %r971, %r1272;
	madc.hi.u32     %r1272, %r970, %r971,  0;
	}
	// end inline asm
	st.local.u32 	[%r1271], %r968;
	add.s32 	%r1271, %r1271, 4;
	add.s64 	%rd332, %rd332, 4;
	setp.ne.s64 	%p156, %rd332, 24;
	@%p156 bra 	$L__BB0_184;
// %bb.185:
	st.local.u32 	[%r9+24], %r1272;
	shl.b32 	%r973, %r290, 2;
	sub.s32 	%r295, %r9, %r973;
	ld.local.u32 	%r296, [%r295+24];
	ld.local.u32 	%r297, [%r295+20];
	and.b32  	%r975, %r771, 260046848;
	setp.eq.s32 	%p157, %r975, 0;
	mov.u32 	%r1273, %r297;
	@%p157 bra 	$L__BB0_187;
// %bb.186:
	ld.local.u32 	%r976, [%r295+16];
	shf.l.wrap.b32 	%r1273, %r976, %r297, %r288;
$L__BB0_187:                            // %__internal_trig_reduction_slowpath.exit.i.i.i788
	shf.l.wrap.b32 	%r977, %r297, %r296, %r288;
	shr.u32 	%r978, %r977, 30;
	shf.l.wrap.b32 	%r979, %r1273, %r977, 2;
	shl.b32 	%r980, %r1273, 2;
	shr.u32 	%r981, %r979, 31;
	add.s32 	%r982, %r981, %r978;
	neg.s32 	%r983, %r982;
	setp.lt.s32 	%p158, %r771, 0;
	selp.b32 	%r1274, %r983, %r982, %p158;
	xor.b32  	%r984, %r979, %r771;
	shr.s32 	%r985, %r979, 31;
	xor.b32  	%r986, %r985, %r979;
	xor.b32  	%r987, %r985, %r980;
	cvt.u64.u32 	%rd255, %r986;
	shl.b64 	%rd256, %rd255, 32;
	cvt.u64.u32 	%rd257, %r987;
	or.b64  	%rd258, %rd256, %rd257;
	cvt.rn.f64.s64 	%fd31, %rd258;
	mul.f64 	%fd32, %fd31, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f722, %fd32;
	neg.f32 	%f723, %f722;
	setp.lt.s32 	%p159, %r984, 0;
	selp.f32 	%f1068, %f723, %f722, %p159;
$L__BB0_188:                            // %__internal_trig_reduction_kernel.exit.i.i799
	mul.rn.ftz.f32 	%f255, %f1068, %f1068;
	and.b32  	%r989, %r1274, 1;
	setp.eq.b32 	%p160, %r989, 1;
	not.pred 	%p161, %p160;
	selp.f32 	%f256, 0f3F800000, %f1068, %p160;
	mov.f32 	%f728, 0f00000000;
	fma.rn.ftz.f32 	%f257, %f255, %f256, %f728;
	mov.f32 	%f1071, 0fB94D4153;
	mov.f32 	%f1070, 0f3C0885E4;
	mov.f32 	%f1069, 0fBE2AAAA8;
	@%p161 bra 	$L__BB0_190;
// %bb.189:                             // %__internal_fmad.exit1.i.i.i807
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f729, 0fBAB607ED;
	mov.f32 	%f730, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1071, %f730, %f255, %f729;
	mov.f32 	%f1070, 0f3D2AAABB;
	mov.f32 	%f1069, 0fBEFFFFFF;
$L__BB0_190:                            // %__internal_fmad.exit2.i.i.i810
	mov.b32 	%f1, %r434;
	.loc	1 45 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:45:24
	fma.rn.ftz.f32 	%f733, %f1071, %f255, %f1070;
	fma.rn.ftz.f32 	%f734, %f733, %f255, %f1069;
	fma.rn.ftz.f32 	%f1072, %f734, %f257, %f256;
	and.b32  	%r990, %r1274, 2;
	setp.eq.s32 	%p162, %r990, 0;
	@%p162 bra 	$L__BB0_192;
// %bb.191:                             // %__internal_fmad.exit5.i.i.i818
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f736, 0fBF800000;
	fma.rn.ftz.f32 	%f1072, %f1072, %f736, %f728;
$L__BB0_192:                            // %__nv_sinf.exit825
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f737, %f1, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1278, %f737;
	cvt.rn.f32.s32 	%f738, %r1278;
	mov.f32 	%f739, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f740, %f738, %f739, %f1;
	mov.f32 	%f741, 0fB3A22168;
	fma.rn.ftz.f32 	%f742, %f738, %f741, %f740;
	mov.f32 	%f743, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1073, %f738, %f743, %f742;
	abs.ftz.f32 	%f266, %f1;
	setp.ltu.f32 	%p163, %f266, 0f47CE4780;
	@%p163 bra 	$L__BB0_200;
// %bb.193:                             // %__nv_isinff.exit.i.i.i837
	setp.neu.f32 	%p164, %f266, 0f7F800000;
	@%p164 bra 	$L__BB0_195;
// %bb.194:                             // %__nv_fmul_rn.exit.i.i.i876
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f746, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1073, %f1, %f746;
	mov.b32 	%r1278, 0;
	bra.uni 	$L__BB0_200;
$L__BB0_195:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r8, %rd94;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r303, %r434, 23;
	and.b32  	%r992, %r303, 224;
	add.s32 	%r993, %r992, -128;
	shl.b32 	%r994, %r434, 8;
	or.b32  	%r998, %r994, -2147483648;
	shr.u32 	%r305, %r993, 5;
	mov.b32 	%r1276, 0;
	mov.b64 	%rd333, 0;
	mov.u64 	%rd260, __cudart_i2opi_f;
	mov.u32 	%r1275, %r8;
$L__BB0_196:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd261, %rd260, %rd333;
	ld.global.nc.u32 	%r997, [%rd261];
	// begin inline asm
	{
	mad.lo.cc.u32   %r995, %r997, %r998, %r1276;
	madc.hi.u32     %r1276, %r997, %r998,  0;
	}
	// end inline asm
	st.local.u32 	[%r1275], %r995;
	add.s32 	%r1275, %r1275, 4;
	add.s64 	%rd333, %rd333, 4;
	setp.ne.s64 	%p165, %rd333, 24;
	@%p165 bra 	$L__BB0_196;
// %bb.197:
	st.local.u32 	[%r8+24], %r1276;
	shl.b32 	%r1000, %r305, 2;
	sub.s32 	%r310, %r8, %r1000;
	ld.local.u32 	%r311, [%r310+24];
	ld.local.u32 	%r312, [%r310+20];
	and.b32  	%r1002, %r434, 260046848;
	setp.eq.s32 	%p166, %r1002, 0;
	mov.u32 	%r1277, %r312;
	@%p166 bra 	$L__BB0_199;
// %bb.198:
	ld.local.u32 	%r1003, [%r310+16];
	shf.l.wrap.b32 	%r1277, %r1003, %r312, %r303;
$L__BB0_199:                            // %__internal_trig_reduction_slowpath.exit.i.i.i843
	shf.l.wrap.b32 	%r1004, %r312, %r311, %r303;
	shr.u32 	%r1005, %r1004, 30;
	shf.l.wrap.b32 	%r1006, %r1277, %r1004, 2;
	shl.b32 	%r1007, %r1277, 2;
	shr.u32 	%r1008, %r1006, 31;
	add.s32 	%r1009, %r1008, %r1005;
	neg.s32 	%r1010, %r1009;
	setp.lt.s32 	%p167, %r434, 0;
	selp.b32 	%r1278, %r1010, %r1009, %p167;
	xor.b32  	%r1011, %r1006, %r434;
	shr.s32 	%r1012, %r1006, 31;
	xor.b32  	%r1013, %r1012, %r1006;
	xor.b32  	%r1014, %r1012, %r1007;
	cvt.u64.u32 	%rd262, %r1013;
	shl.b64 	%rd263, %rd262, 32;
	cvt.u64.u32 	%rd264, %r1014;
	or.b64  	%rd265, %rd263, %rd264;
	cvt.rn.f64.s64 	%fd33, %rd265;
	mul.f64 	%fd34, %fd33, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f744, %fd34;
	neg.f32 	%f745, %f744;
	setp.lt.s32 	%p168, %r1011, 0;
	selp.f32 	%f1073, %f745, %f744, %p168;
$L__BB0_200:                            // %__internal_trig_reduction_kernel.exit.i.i854
	add.s32 	%r317, %r1278, 1;
	mul.rn.ftz.f32 	%f270, %f1073, %f1073;
	and.b32  	%r1016, %r1278, 1;
	setp.eq.b32 	%p169, %r1016, 1;
	selp.f32 	%f271, %f1073, 0f3F800000, %p169;
	mov.f32 	%f750, 0f00000000;
	fma.rn.ftz.f32 	%f272, %f270, %f271, %f750;
	mov.f32 	%f1076, 0fB94D4153;
	mov.f32 	%f1075, 0f3C0885E4;
	mov.f32 	%f1074, 0fBE2AAAA8;
	@%p169 bra 	$L__BB0_202;
// %bb.201:                             // %__internal_fmad.exit1.i.i.i873
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f751, 0fBAB607ED;
	mov.f32 	%f752, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1076, %f752, %f270, %f751;
	mov.f32 	%f1075, 0f3D2AAABB;
	mov.f32 	%f1074, 0fBEFFFFFF;
$L__BB0_202:                            // %__internal_fmad.exit2.i.i.i861
	mov.b32 	%f2, %r435;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f755, %f1076, %f270, %f1075;
	fma.rn.ftz.f32 	%f756, %f755, %f270, %f1074;
	fma.rn.ftz.f32 	%f1077, %f756, %f272, %f271;
	and.b32  	%r1017, %r317, 2;
	setp.eq.s32 	%p170, %r1017, 0;
	@%p170 bra 	$L__BB0_204;
// %bb.203:                             // %__internal_fmad.exit5.i.i.i869
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f758, 0fBF800000;
	fma.rn.ftz.f32 	%f1077, %f1077, %f758, %f750;
$L__BB0_204:                            // %__nv_cosf.exit
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f759, %f2, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1282, %f759;
	cvt.rn.f32.s32 	%f760, %r1282;
	mov.f32 	%f761, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f762, %f760, %f761, %f2;
	mov.f32 	%f763, 0fB3A22168;
	fma.rn.ftz.f32 	%f764, %f760, %f763, %f762;
	mov.f32 	%f765, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1078, %f760, %f765, %f764;
	abs.ftz.f32 	%f281, %f2;
	setp.ltu.f32 	%p171, %f281, 0f47CE4780;
	@%p171 bra 	$L__BB0_212;
// %bb.205:                             // %__nv_isinff.exit.i.i.i890
	setp.neu.f32 	%p172, %f281, 0f7F800000;
	@%p172 bra 	$L__BB0_207;
// %bb.206:                             // %__nv_fmul_rn.exit.i.i.i930
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f768, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1078, %f2, %f768;
	mov.b32 	%r1282, 0;
	bra.uni 	$L__BB0_212;
$L__BB0_207:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r7, %rd92;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r319, %r435, 23;
	and.b32  	%r1019, %r319, 224;
	add.s32 	%r1020, %r1019, -128;
	shl.b32 	%r1021, %r435, 8;
	or.b32  	%r1025, %r1021, -2147483648;
	shr.u32 	%r321, %r1020, 5;
	mov.b32 	%r1280, 0;
	mov.b64 	%rd334, 0;
	mov.u64 	%rd267, __cudart_i2opi_f;
	mov.u32 	%r1279, %r7;
$L__BB0_208:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd268, %rd267, %rd334;
	ld.global.nc.u32 	%r1024, [%rd268];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1022, %r1024, %r1025, %r1280;
	madc.hi.u32     %r1280, %r1024, %r1025,  0;
	}
	// end inline asm
	st.local.u32 	[%r1279], %r1022;
	add.s32 	%r1279, %r1279, 4;
	add.s64 	%rd334, %rd334, 4;
	setp.ne.s64 	%p173, %rd334, 24;
	@%p173 bra 	$L__BB0_208;
// %bb.209:
	st.local.u32 	[%r7+24], %r1280;
	shl.b32 	%r1027, %r321, 2;
	sub.s32 	%r326, %r7, %r1027;
	ld.local.u32 	%r327, [%r326+24];
	ld.local.u32 	%r328, [%r326+20];
	and.b32  	%r1029, %r435, 260046848;
	setp.eq.s32 	%p174, %r1029, 0;
	mov.u32 	%r1281, %r328;
	@%p174 bra 	$L__BB0_211;
// %bb.210:
	ld.local.u32 	%r1030, [%r326+16];
	shf.l.wrap.b32 	%r1281, %r1030, %r328, %r319;
$L__BB0_211:                            // %__internal_trig_reduction_slowpath.exit.i.i.i896
	shf.l.wrap.b32 	%r1031, %r328, %r327, %r319;
	shr.u32 	%r1032, %r1031, 30;
	shf.l.wrap.b32 	%r1033, %r1281, %r1031, 2;
	shl.b32 	%r1034, %r1281, 2;
	shr.u32 	%r1035, %r1033, 31;
	add.s32 	%r1036, %r1035, %r1032;
	neg.s32 	%r1037, %r1036;
	setp.lt.s32 	%p175, %r435, 0;
	selp.b32 	%r1282, %r1037, %r1036, %p175;
	xor.b32  	%r1038, %r1033, %r435;
	shr.s32 	%r1039, %r1033, 31;
	xor.b32  	%r1040, %r1039, %r1033;
	xor.b32  	%r1041, %r1039, %r1034;
	cvt.u64.u32 	%rd269, %r1040;
	shl.b64 	%rd270, %rd269, 32;
	cvt.u64.u32 	%rd271, %r1041;
	or.b64  	%rd272, %rd270, %rd271;
	cvt.rn.f64.s64 	%fd35, %rd272;
	mul.f64 	%fd36, %fd35, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f766, %fd36;
	neg.f32 	%f767, %f766;
	setp.lt.s32 	%p176, %r1038, 0;
	selp.f32 	%f1078, %f767, %f766, %p176;
$L__BB0_212:                            // %__internal_trig_reduction_kernel.exit.i.i907
	add.s32 	%r333, %r1282, 1;
	mul.rn.ftz.f32 	%f285, %f1078, %f1078;
	and.b32  	%r1043, %r1282, 1;
	setp.eq.b32 	%p177, %r1043, 1;
	selp.f32 	%f286, %f1078, 0f3F800000, %p177;
	mov.f32 	%f772, 0f00000000;
	fma.rn.ftz.f32 	%f287, %f285, %f286, %f772;
	mov.f32 	%f1081, 0fB94D4153;
	mov.f32 	%f1080, 0f3C0885E4;
	mov.f32 	%f1079, 0fBE2AAAA8;
	@%p177 bra 	$L__BB0_214;
// %bb.213:                             // %__internal_fmad.exit1.i.i.i927
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f773, 0fBAB607ED;
	mov.f32 	%f774, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1081, %f774, %f285, %f773;
	mov.f32 	%f1080, 0f3D2AAABB;
	mov.f32 	%f1079, 0fBEFFFFFF;
$L__BB0_214:                            // %__internal_fmad.exit2.i.i.i915
	mov.b32 	%f3, %r436;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f777, %f1081, %f285, %f1080;
	fma.rn.ftz.f32 	%f778, %f777, %f285, %f1079;
	fma.rn.ftz.f32 	%f1082, %f778, %f287, %f286;
	and.b32  	%r1044, %r333, 2;
	setp.eq.s32 	%p178, %r1044, 0;
	@%p178 bra 	$L__BB0_216;
// %bb.215:                             // %__internal_fmad.exit5.i.i.i923
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f780, 0fBF800000;
	fma.rn.ftz.f32 	%f1082, %f1082, %f780, %f772;
$L__BB0_216:                            // %__nv_cosf.exit933
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f781, %f3, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1286, %f781;
	cvt.rn.f32.s32 	%f782, %r1286;
	mov.f32 	%f783, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f784, %f782, %f783, %f3;
	mov.f32 	%f785, 0fB3A22168;
	fma.rn.ftz.f32 	%f786, %f782, %f785, %f784;
	mov.f32 	%f787, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1083, %f782, %f787, %f786;
	abs.ftz.f32 	%f296, %f3;
	setp.ltu.f32 	%p179, %f296, 0f47CE4780;
	@%p179 bra 	$L__BB0_224;
// %bb.217:                             // %__nv_isinff.exit.i.i.i945
	setp.neu.f32 	%p180, %f296, 0f7F800000;
	@%p180 bra 	$L__BB0_219;
// %bb.218:                             // %__nv_fmul_rn.exit.i.i.i985
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f790, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1083, %f3, %f790;
	mov.b32 	%r1286, 0;
	bra.uni 	$L__BB0_224;
$L__BB0_219:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r6, %rd90;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r335, %r436, 23;
	and.b32  	%r1046, %r335, 224;
	add.s32 	%r1047, %r1046, -128;
	shl.b32 	%r1048, %r436, 8;
	or.b32  	%r1052, %r1048, -2147483648;
	shr.u32 	%r337, %r1047, 5;
	mov.b32 	%r1284, 0;
	mov.b64 	%rd335, 0;
	mov.u64 	%rd274, __cudart_i2opi_f;
	mov.u32 	%r1283, %r6;
$L__BB0_220:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd275, %rd274, %rd335;
	ld.global.nc.u32 	%r1051, [%rd275];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1049, %r1051, %r1052, %r1284;
	madc.hi.u32     %r1284, %r1051, %r1052,  0;
	}
	// end inline asm
	st.local.u32 	[%r1283], %r1049;
	add.s32 	%r1283, %r1283, 4;
	add.s64 	%rd335, %rd335, 4;
	setp.ne.s64 	%p181, %rd335, 24;
	@%p181 bra 	$L__BB0_220;
// %bb.221:
	st.local.u32 	[%r6+24], %r1284;
	shl.b32 	%r1054, %r337, 2;
	sub.s32 	%r342, %r6, %r1054;
	ld.local.u32 	%r343, [%r342+24];
	ld.local.u32 	%r344, [%r342+20];
	and.b32  	%r1056, %r436, 260046848;
	setp.eq.s32 	%p182, %r1056, 0;
	mov.u32 	%r1285, %r344;
	@%p182 bra 	$L__BB0_223;
// %bb.222:
	ld.local.u32 	%r1057, [%r342+16];
	shf.l.wrap.b32 	%r1285, %r1057, %r344, %r335;
$L__BB0_223:                            // %__internal_trig_reduction_slowpath.exit.i.i.i951
	shf.l.wrap.b32 	%r1058, %r344, %r343, %r335;
	shr.u32 	%r1059, %r1058, 30;
	shf.l.wrap.b32 	%r1060, %r1285, %r1058, 2;
	shl.b32 	%r1061, %r1285, 2;
	shr.u32 	%r1062, %r1060, 31;
	add.s32 	%r1063, %r1062, %r1059;
	neg.s32 	%r1064, %r1063;
	setp.lt.s32 	%p183, %r436, 0;
	selp.b32 	%r1286, %r1064, %r1063, %p183;
	xor.b32  	%r1065, %r1060, %r436;
	shr.s32 	%r1066, %r1060, 31;
	xor.b32  	%r1067, %r1066, %r1060;
	xor.b32  	%r1068, %r1066, %r1061;
	cvt.u64.u32 	%rd276, %r1067;
	shl.b64 	%rd277, %rd276, 32;
	cvt.u64.u32 	%rd278, %r1068;
	or.b64  	%rd279, %rd277, %rd278;
	cvt.rn.f64.s64 	%fd37, %rd279;
	mul.f64 	%fd38, %fd37, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f788, %fd38;
	neg.f32 	%f789, %f788;
	setp.lt.s32 	%p184, %r1065, 0;
	selp.f32 	%f1083, %f789, %f788, %p184;
$L__BB0_224:                            // %__internal_trig_reduction_kernel.exit.i.i962
	add.s32 	%r349, %r1286, 1;
	mul.rn.ftz.f32 	%f300, %f1083, %f1083;
	and.b32  	%r1070, %r1286, 1;
	setp.eq.b32 	%p185, %r1070, 1;
	selp.f32 	%f301, %f1083, 0f3F800000, %p185;
	mov.f32 	%f794, 0f00000000;
	fma.rn.ftz.f32 	%f302, %f300, %f301, %f794;
	mov.f32 	%f1086, 0fB94D4153;
	mov.f32 	%f1085, 0f3C0885E4;
	mov.f32 	%f1084, 0fBE2AAAA8;
	@%p185 bra 	$L__BB0_226;
// %bb.225:                             // %__internal_fmad.exit1.i.i.i982
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f795, 0fBAB607ED;
	mov.f32 	%f796, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1086, %f796, %f300, %f795;
	mov.f32 	%f1085, 0f3D2AAABB;
	mov.f32 	%f1084, 0fBEFFFFFF;
$L__BB0_226:                            // %__internal_fmad.exit2.i.i.i970
	mov.b32 	%f4, %r437;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f799, %f1086, %f300, %f1085;
	fma.rn.ftz.f32 	%f800, %f799, %f300, %f1084;
	fma.rn.ftz.f32 	%f1087, %f800, %f302, %f301;
	and.b32  	%r1071, %r349, 2;
	setp.eq.s32 	%p186, %r1071, 0;
	@%p186 bra 	$L__BB0_228;
// %bb.227:                             // %__internal_fmad.exit5.i.i.i978
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f802, 0fBF800000;
	fma.rn.ftz.f32 	%f1087, %f1087, %f802, %f794;
$L__BB0_228:                            // %__nv_cosf.exit988
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f803, %f4, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1290, %f803;
	cvt.rn.f32.s32 	%f804, %r1290;
	mov.f32 	%f805, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f806, %f804, %f805, %f4;
	mov.f32 	%f807, 0fB3A22168;
	fma.rn.ftz.f32 	%f808, %f804, %f807, %f806;
	mov.f32 	%f809, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1088, %f804, %f809, %f808;
	abs.ftz.f32 	%f311, %f4;
	setp.ltu.f32 	%p187, %f311, 0f47CE4780;
	@%p187 bra 	$L__BB0_236;
// %bb.229:                             // %__nv_isinff.exit.i.i.i1000
	setp.neu.f32 	%p188, %f311, 0f7F800000;
	@%p188 bra 	$L__BB0_231;
// %bb.230:                             // %__nv_fmul_rn.exit.i.i.i1040
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f812, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1088, %f4, %f812;
	mov.b32 	%r1290, 0;
	bra.uni 	$L__BB0_236;
$L__BB0_231:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r5, %rd88;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r351, %r437, 23;
	and.b32  	%r1073, %r351, 224;
	add.s32 	%r1074, %r1073, -128;
	shl.b32 	%r1075, %r437, 8;
	or.b32  	%r1079, %r1075, -2147483648;
	shr.u32 	%r353, %r1074, 5;
	mov.b32 	%r1288, 0;
	mov.b64 	%rd336, 0;
	mov.u64 	%rd281, __cudart_i2opi_f;
	mov.u32 	%r1287, %r5;
$L__BB0_232:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd282, %rd281, %rd336;
	ld.global.nc.u32 	%r1078, [%rd282];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1076, %r1078, %r1079, %r1288;
	madc.hi.u32     %r1288, %r1078, %r1079,  0;
	}
	// end inline asm
	st.local.u32 	[%r1287], %r1076;
	add.s32 	%r1287, %r1287, 4;
	add.s64 	%rd336, %rd336, 4;
	setp.ne.s64 	%p189, %rd336, 24;
	@%p189 bra 	$L__BB0_232;
// %bb.233:
	st.local.u32 	[%r5+24], %r1288;
	shl.b32 	%r1081, %r353, 2;
	sub.s32 	%r358, %r5, %r1081;
	ld.local.u32 	%r359, [%r358+24];
	ld.local.u32 	%r360, [%r358+20];
	and.b32  	%r1083, %r437, 260046848;
	setp.eq.s32 	%p190, %r1083, 0;
	mov.u32 	%r1289, %r360;
	@%p190 bra 	$L__BB0_235;
// %bb.234:
	ld.local.u32 	%r1084, [%r358+16];
	shf.l.wrap.b32 	%r1289, %r1084, %r360, %r351;
$L__BB0_235:                            // %__internal_trig_reduction_slowpath.exit.i.i.i1006
	shf.l.wrap.b32 	%r1085, %r360, %r359, %r351;
	shr.u32 	%r1086, %r1085, 30;
	shf.l.wrap.b32 	%r1087, %r1289, %r1085, 2;
	shl.b32 	%r1088, %r1289, 2;
	shr.u32 	%r1089, %r1087, 31;
	add.s32 	%r1090, %r1089, %r1086;
	neg.s32 	%r1091, %r1090;
	setp.lt.s32 	%p191, %r437, 0;
	selp.b32 	%r1290, %r1091, %r1090, %p191;
	xor.b32  	%r1092, %r1087, %r437;
	shr.s32 	%r1093, %r1087, 31;
	xor.b32  	%r1094, %r1093, %r1087;
	xor.b32  	%r1095, %r1093, %r1088;
	cvt.u64.u32 	%rd283, %r1094;
	shl.b64 	%rd284, %rd283, 32;
	cvt.u64.u32 	%rd285, %r1095;
	or.b64  	%rd286, %rd284, %rd285;
	cvt.rn.f64.s64 	%fd39, %rd286;
	mul.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f810, %fd40;
	neg.f32 	%f811, %f810;
	setp.lt.s32 	%p192, %r1092, 0;
	selp.f32 	%f1088, %f811, %f810, %p192;
$L__BB0_236:                            // %__internal_trig_reduction_kernel.exit.i.i1017
	add.s32 	%r365, %r1290, 1;
	mul.rn.ftz.f32 	%f315, %f1088, %f1088;
	and.b32  	%r1097, %r1290, 1;
	setp.eq.b32 	%p193, %r1097, 1;
	selp.f32 	%f316, %f1088, 0f3F800000, %p193;
	mov.f32 	%f816, 0f00000000;
	fma.rn.ftz.f32 	%f317, %f315, %f316, %f816;
	mov.f32 	%f1091, 0fB94D4153;
	mov.f32 	%f1090, 0f3C0885E4;
	mov.f32 	%f1089, 0fBE2AAAA8;
	@%p193 bra 	$L__BB0_238;
// %bb.237:                             // %__internal_fmad.exit1.i.i.i1037
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f817, 0fBAB607ED;
	mov.f32 	%f818, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1091, %f818, %f315, %f817;
	mov.f32 	%f1090, 0f3D2AAABB;
	mov.f32 	%f1089, 0fBEFFFFFF;
$L__BB0_238:                            // %__internal_fmad.exit2.i.i.i1025
	mov.b32 	%f5, %r438;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f821, %f1091, %f315, %f1090;
	fma.rn.ftz.f32 	%f822, %f821, %f315, %f1089;
	fma.rn.ftz.f32 	%f1092, %f822, %f317, %f316;
	and.b32  	%r1098, %r365, 2;
	setp.eq.s32 	%p194, %r1098, 0;
	@%p194 bra 	$L__BB0_240;
// %bb.239:                             // %__internal_fmad.exit5.i.i.i1033
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f824, 0fBF800000;
	fma.rn.ftz.f32 	%f1092, %f1092, %f824, %f816;
$L__BB0_240:                            // %__nv_cosf.exit1043
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f825, %f5, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1294, %f825;
	cvt.rn.f32.s32 	%f826, %r1294;
	mov.f32 	%f827, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f828, %f826, %f827, %f5;
	mov.f32 	%f829, 0fB3A22168;
	fma.rn.ftz.f32 	%f830, %f826, %f829, %f828;
	mov.f32 	%f831, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1093, %f826, %f831, %f830;
	abs.ftz.f32 	%f326, %f5;
	setp.ltu.f32 	%p195, %f326, 0f47CE4780;
	@%p195 bra 	$L__BB0_248;
// %bb.241:                             // %__nv_isinff.exit.i.i.i1055
	setp.neu.f32 	%p196, %f326, 0f7F800000;
	@%p196 bra 	$L__BB0_243;
// %bb.242:                             // %__nv_fmul_rn.exit.i.i.i1095
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f834, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1093, %f5, %f834;
	mov.b32 	%r1294, 0;
	bra.uni 	$L__BB0_248;
$L__BB0_243:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r4, %rd86;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r367, %r438, 23;
	and.b32  	%r1100, %r367, 224;
	add.s32 	%r1101, %r1100, -128;
	shl.b32 	%r1102, %r438, 8;
	or.b32  	%r1106, %r1102, -2147483648;
	shr.u32 	%r369, %r1101, 5;
	mov.b32 	%r1292, 0;
	mov.b64 	%rd337, 0;
	mov.u64 	%rd288, __cudart_i2opi_f;
	mov.u32 	%r1291, %r4;
$L__BB0_244:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd289, %rd288, %rd337;
	ld.global.nc.u32 	%r1105, [%rd289];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1103, %r1105, %r1106, %r1292;
	madc.hi.u32     %r1292, %r1105, %r1106,  0;
	}
	// end inline asm
	st.local.u32 	[%r1291], %r1103;
	add.s32 	%r1291, %r1291, 4;
	add.s64 	%rd337, %rd337, 4;
	setp.ne.s64 	%p197, %rd337, 24;
	@%p197 bra 	$L__BB0_244;
// %bb.245:
	st.local.u32 	[%r4+24], %r1292;
	shl.b32 	%r1108, %r369, 2;
	sub.s32 	%r374, %r4, %r1108;
	ld.local.u32 	%r375, [%r374+24];
	ld.local.u32 	%r376, [%r374+20];
	and.b32  	%r1110, %r438, 260046848;
	setp.eq.s32 	%p198, %r1110, 0;
	mov.u32 	%r1293, %r376;
	@%p198 bra 	$L__BB0_247;
// %bb.246:
	ld.local.u32 	%r1111, [%r374+16];
	shf.l.wrap.b32 	%r1293, %r1111, %r376, %r367;
$L__BB0_247:                            // %__internal_trig_reduction_slowpath.exit.i.i.i1061
	shf.l.wrap.b32 	%r1112, %r376, %r375, %r367;
	shr.u32 	%r1113, %r1112, 30;
	shf.l.wrap.b32 	%r1114, %r1293, %r1112, 2;
	shl.b32 	%r1115, %r1293, 2;
	shr.u32 	%r1116, %r1114, 31;
	add.s32 	%r1117, %r1116, %r1113;
	neg.s32 	%r1118, %r1117;
	setp.lt.s32 	%p199, %r438, 0;
	selp.b32 	%r1294, %r1118, %r1117, %p199;
	xor.b32  	%r1119, %r1114, %r438;
	shr.s32 	%r1120, %r1114, 31;
	xor.b32  	%r1121, %r1120, %r1114;
	xor.b32  	%r1122, %r1120, %r1115;
	cvt.u64.u32 	%rd290, %r1121;
	shl.b64 	%rd291, %rd290, 32;
	cvt.u64.u32 	%rd292, %r1122;
	or.b64  	%rd293, %rd291, %rd292;
	cvt.rn.f64.s64 	%fd41, %rd293;
	mul.f64 	%fd42, %fd41, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f832, %fd42;
	neg.f32 	%f833, %f832;
	setp.lt.s32 	%p200, %r1119, 0;
	selp.f32 	%f1093, %f833, %f832, %p200;
$L__BB0_248:                            // %__internal_trig_reduction_kernel.exit.i.i1072
	add.s32 	%r381, %r1294, 1;
	mul.rn.ftz.f32 	%f330, %f1093, %f1093;
	and.b32  	%r1124, %r1294, 1;
	setp.eq.b32 	%p201, %r1124, 1;
	selp.f32 	%f331, %f1093, 0f3F800000, %p201;
	mov.f32 	%f838, 0f00000000;
	fma.rn.ftz.f32 	%f332, %f330, %f331, %f838;
	mov.f32 	%f1096, 0fB94D4153;
	mov.f32 	%f1095, 0f3C0885E4;
	mov.f32 	%f1094, 0fBE2AAAA8;
	@%p201 bra 	$L__BB0_250;
// %bb.249:                             // %__internal_fmad.exit1.i.i.i1092
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f839, 0fBAB607ED;
	mov.f32 	%f840, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1096, %f840, %f330, %f839;
	mov.f32 	%f1095, 0f3D2AAABB;
	mov.f32 	%f1094, 0fBEFFFFFF;
$L__BB0_250:                            // %__internal_fmad.exit2.i.i.i1080
	mov.b32 	%f6, %r439;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f843, %f1096, %f330, %f1095;
	fma.rn.ftz.f32 	%f844, %f843, %f330, %f1094;
	fma.rn.ftz.f32 	%f1097, %f844, %f332, %f331;
	and.b32  	%r1125, %r381, 2;
	setp.eq.s32 	%p202, %r1125, 0;
	@%p202 bra 	$L__BB0_252;
// %bb.251:                             // %__internal_fmad.exit5.i.i.i1088
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f846, 0fBF800000;
	fma.rn.ftz.f32 	%f1097, %f1097, %f846, %f838;
$L__BB0_252:                            // %__nv_cosf.exit1098
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f847, %f6, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1298, %f847;
	cvt.rn.f32.s32 	%f848, %r1298;
	mov.f32 	%f849, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f850, %f848, %f849, %f6;
	mov.f32 	%f851, 0fB3A22168;
	fma.rn.ftz.f32 	%f852, %f848, %f851, %f850;
	mov.f32 	%f853, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1098, %f848, %f853, %f852;
	abs.ftz.f32 	%f341, %f6;
	setp.ltu.f32 	%p203, %f341, 0f47CE4780;
	@%p203 bra 	$L__BB0_260;
// %bb.253:                             // %__nv_isinff.exit.i.i.i1110
	setp.neu.f32 	%p204, %f341, 0f7F800000;
	@%p204 bra 	$L__BB0_255;
// %bb.254:                             // %__nv_fmul_rn.exit.i.i.i1150
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f856, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1098, %f6, %f856;
	mov.b32 	%r1298, 0;
	bra.uni 	$L__BB0_260;
$L__BB0_255:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r3, %rd84;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r383, %r439, 23;
	and.b32  	%r1127, %r383, 224;
	add.s32 	%r1128, %r1127, -128;
	shl.b32 	%r1129, %r439, 8;
	or.b32  	%r1133, %r1129, -2147483648;
	shr.u32 	%r385, %r1128, 5;
	mov.b32 	%r1296, 0;
	mov.b64 	%rd338, 0;
	mov.u64 	%rd295, __cudart_i2opi_f;
	mov.u32 	%r1295, %r3;
$L__BB0_256:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd296, %rd295, %rd338;
	ld.global.nc.u32 	%r1132, [%rd296];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1130, %r1132, %r1133, %r1296;
	madc.hi.u32     %r1296, %r1132, %r1133,  0;
	}
	// end inline asm
	st.local.u32 	[%r1295], %r1130;
	add.s32 	%r1295, %r1295, 4;
	add.s64 	%rd338, %rd338, 4;
	setp.ne.s64 	%p205, %rd338, 24;
	@%p205 bra 	$L__BB0_256;
// %bb.257:
	st.local.u32 	[%r3+24], %r1296;
	shl.b32 	%r1135, %r385, 2;
	sub.s32 	%r390, %r3, %r1135;
	ld.local.u32 	%r391, [%r390+24];
	ld.local.u32 	%r392, [%r390+20];
	and.b32  	%r1137, %r439, 260046848;
	setp.eq.s32 	%p206, %r1137, 0;
	mov.u32 	%r1297, %r392;
	@%p206 bra 	$L__BB0_259;
// %bb.258:
	ld.local.u32 	%r1138, [%r390+16];
	shf.l.wrap.b32 	%r1297, %r1138, %r392, %r383;
$L__BB0_259:                            // %__internal_trig_reduction_slowpath.exit.i.i.i1116
	shf.l.wrap.b32 	%r1139, %r392, %r391, %r383;
	shr.u32 	%r1140, %r1139, 30;
	shf.l.wrap.b32 	%r1141, %r1297, %r1139, 2;
	shl.b32 	%r1142, %r1297, 2;
	shr.u32 	%r1143, %r1141, 31;
	add.s32 	%r1144, %r1143, %r1140;
	neg.s32 	%r1145, %r1144;
	setp.lt.s32 	%p207, %r439, 0;
	selp.b32 	%r1298, %r1145, %r1144, %p207;
	xor.b32  	%r1146, %r1141, %r439;
	shr.s32 	%r1147, %r1141, 31;
	xor.b32  	%r1148, %r1147, %r1141;
	xor.b32  	%r1149, %r1147, %r1142;
	cvt.u64.u32 	%rd297, %r1148;
	shl.b64 	%rd298, %rd297, 32;
	cvt.u64.u32 	%rd299, %r1149;
	or.b64  	%rd300, %rd298, %rd299;
	cvt.rn.f64.s64 	%fd43, %rd300;
	mul.f64 	%fd44, %fd43, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f854, %fd44;
	neg.f32 	%f855, %f854;
	setp.lt.s32 	%p208, %r1146, 0;
	selp.f32 	%f1098, %f855, %f854, %p208;
$L__BB0_260:                            // %__internal_trig_reduction_kernel.exit.i.i1127
	add.s32 	%r397, %r1298, 1;
	mul.rn.ftz.f32 	%f345, %f1098, %f1098;
	and.b32  	%r1151, %r1298, 1;
	setp.eq.b32 	%p209, %r1151, 1;
	selp.f32 	%f346, %f1098, 0f3F800000, %p209;
	mov.f32 	%f860, 0f00000000;
	fma.rn.ftz.f32 	%f347, %f345, %f346, %f860;
	mov.f32 	%f1101, 0fB94D4153;
	mov.f32 	%f1100, 0f3C0885E4;
	mov.f32 	%f1099, 0fBE2AAAA8;
	@%p209 bra 	$L__BB0_262;
// %bb.261:                             // %__internal_fmad.exit1.i.i.i1147
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f861, 0fBAB607ED;
	mov.f32 	%f862, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1101, %f862, %f345, %f861;
	mov.f32 	%f1100, 0f3D2AAABB;
	mov.f32 	%f1099, 0fBEFFFFFF;
$L__BB0_262:                            // %__internal_fmad.exit2.i.i.i1135
	mov.b32 	%f7, %r440;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f865, %f1101, %f345, %f1100;
	fma.rn.ftz.f32 	%f866, %f865, %f345, %f1099;
	fma.rn.ftz.f32 	%f1102, %f866, %f347, %f346;
	and.b32  	%r1152, %r397, 2;
	setp.eq.s32 	%p210, %r1152, 0;
	@%p210 bra 	$L__BB0_264;
// %bb.263:                             // %__internal_fmad.exit5.i.i.i1143
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f868, 0fBF800000;
	fma.rn.ftz.f32 	%f1102, %f1102, %f868, %f860;
$L__BB0_264:                            // %__nv_cosf.exit1153
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f869, %f7, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1302, %f869;
	cvt.rn.f32.s32 	%f870, %r1302;
	mov.f32 	%f871, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f872, %f870, %f871, %f7;
	mov.f32 	%f873, 0fB3A22168;
	fma.rn.ftz.f32 	%f874, %f870, %f873, %f872;
	mov.f32 	%f875, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1103, %f870, %f875, %f874;
	abs.ftz.f32 	%f356, %f7;
	setp.ltu.f32 	%p211, %f356, 0f47CE4780;
	@%p211 bra 	$L__BB0_272;
// %bb.265:                             // %__nv_isinff.exit.i.i.i1165
	setp.neu.f32 	%p212, %f356, 0f7F800000;
	@%p212 bra 	$L__BB0_267;
// %bb.266:                             // %__nv_fmul_rn.exit.i.i.i1205
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f878, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1103, %f7, %f878;
	mov.b32 	%r1302, 0;
	bra.uni 	$L__BB0_272;
$L__BB0_267:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r2, %rd82;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r399, %r440, 23;
	and.b32  	%r1154, %r399, 224;
	add.s32 	%r1155, %r1154, -128;
	shl.b32 	%r1156, %r440, 8;
	or.b32  	%r1160, %r1156, -2147483648;
	shr.u32 	%r401, %r1155, 5;
	mov.b32 	%r1300, 0;
	mov.b64 	%rd339, 0;
	mov.u64 	%rd302, __cudart_i2opi_f;
	mov.u32 	%r1299, %r2;
$L__BB0_268:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd303, %rd302, %rd339;
	ld.global.nc.u32 	%r1159, [%rd303];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1157, %r1159, %r1160, %r1300;
	madc.hi.u32     %r1300, %r1159, %r1160,  0;
	}
	// end inline asm
	st.local.u32 	[%r1299], %r1157;
	add.s32 	%r1299, %r1299, 4;
	add.s64 	%rd339, %rd339, 4;
	setp.ne.s64 	%p213, %rd339, 24;
	@%p213 bra 	$L__BB0_268;
// %bb.269:
	st.local.u32 	[%r2+24], %r1300;
	shl.b32 	%r1162, %r401, 2;
	sub.s32 	%r406, %r2, %r1162;
	ld.local.u32 	%r407, [%r406+24];
	ld.local.u32 	%r408, [%r406+20];
	and.b32  	%r1164, %r440, 260046848;
	setp.eq.s32 	%p214, %r1164, 0;
	mov.u32 	%r1301, %r408;
	@%p214 bra 	$L__BB0_271;
// %bb.270:
	ld.local.u32 	%r1165, [%r406+16];
	shf.l.wrap.b32 	%r1301, %r1165, %r408, %r399;
$L__BB0_271:                            // %__internal_trig_reduction_slowpath.exit.i.i.i1171
	shf.l.wrap.b32 	%r1166, %r408, %r407, %r399;
	shr.u32 	%r1167, %r1166, 30;
	shf.l.wrap.b32 	%r1168, %r1301, %r1166, 2;
	shl.b32 	%r1169, %r1301, 2;
	shr.u32 	%r1170, %r1168, 31;
	add.s32 	%r1171, %r1170, %r1167;
	neg.s32 	%r1172, %r1171;
	setp.lt.s32 	%p215, %r440, 0;
	selp.b32 	%r1302, %r1172, %r1171, %p215;
	xor.b32  	%r1173, %r1168, %r440;
	shr.s32 	%r1174, %r1168, 31;
	xor.b32  	%r1175, %r1174, %r1168;
	xor.b32  	%r1176, %r1174, %r1169;
	cvt.u64.u32 	%rd304, %r1175;
	shl.b64 	%rd305, %rd304, 32;
	cvt.u64.u32 	%rd306, %r1176;
	or.b64  	%rd307, %rd305, %rd306;
	cvt.rn.f64.s64 	%fd45, %rd307;
	mul.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f876, %fd46;
	neg.f32 	%f877, %f876;
	setp.lt.s32 	%p216, %r1173, 0;
	selp.f32 	%f1103, %f877, %f876, %p216;
$L__BB0_272:                            // %__internal_trig_reduction_kernel.exit.i.i1182
	add.s32 	%r413, %r1302, 1;
	mul.rn.ftz.f32 	%f360, %f1103, %f1103;
	and.b32  	%r1178, %r1302, 1;
	setp.eq.b32 	%p217, %r1178, 1;
	selp.f32 	%f361, %f1103, 0f3F800000, %p217;
	mov.f32 	%f882, 0f00000000;
	fma.rn.ftz.f32 	%f362, %f360, %f361, %f882;
	mov.f32 	%f1106, 0fB94D4153;
	mov.f32 	%f1105, 0f3C0885E4;
	mov.f32 	%f1104, 0fBE2AAAA8;
	@%p217 bra 	$L__BB0_274;
// %bb.273:                             // %__internal_fmad.exit1.i.i.i1202
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f883, 0fBAB607ED;
	mov.f32 	%f884, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1106, %f884, %f360, %f883;
	mov.f32 	%f1105, 0f3D2AAABB;
	mov.f32 	%f1104, 0fBEFFFFFF;
$L__BB0_274:                            // %__internal_fmad.exit2.i.i.i1190
	mov.b32 	%f8, %r441;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f887, %f1106, %f360, %f1105;
	fma.rn.ftz.f32 	%f888, %f887, %f360, %f1104;
	fma.rn.ftz.f32 	%f1107, %f888, %f362, %f361;
	and.b32  	%r1179, %r413, 2;
	setp.eq.s32 	%p218, %r1179, 0;
	@%p218 bra 	$L__BB0_276;
// %bb.275:                             // %__internal_fmad.exit5.i.i.i1198
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f890, 0fBF800000;
	fma.rn.ftz.f32 	%f1107, %f1107, %f890, %f882;
$L__BB0_276:                            // %__nv_cosf.exit1208
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.f32 	%f891, %f8, 0f3F22F983;
	cvt.rni.ftz.s32.f32 	%r1306, %f891;
	cvt.rn.f32.s32 	%f892, %r1306;
	mov.f32 	%f893, 0fBFC90FDA;
	fma.rn.ftz.f32 	%f894, %f892, %f893, %f8;
	mov.f32 	%f895, 0fB3A22168;
	fma.rn.ftz.f32 	%f896, %f892, %f895, %f894;
	mov.f32 	%f897, 0fA7C234C5;
	fma.rn.ftz.f32 	%f1108, %f892, %f897, %f896;
	abs.ftz.f32 	%f371, %f8;
	setp.ltu.f32 	%p219, %f371, 0f47CE4780;
	@%p219 bra 	$L__BB0_284;
// %bb.277:                             // %__nv_isinff.exit.i.i.i1220
	setp.neu.f32 	%p220, %f371, 0f7F800000;
	@%p220 bra 	$L__BB0_279;
// %bb.278:                             // %__nv_fmul_rn.exit.i.i.i1260
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f900, 0f00000000;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	mul.rn.ftz.f32 	%f1108, %f8, %f900;
	mov.b32 	%r1306, 0;
	bra.uni 	$L__BB0_284;
$L__BB0_279:
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	cvt.u32.u64 	%r1, %rd80;
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	shr.u32 	%r415, %r441, 23;
	and.b32  	%r1181, %r415, 224;
	add.s32 	%r1182, %r1181, -128;
	shl.b32 	%r1183, %r441, 8;
	or.b32  	%r1187, %r1183, -2147483648;
	shr.u32 	%r417, %r1182, 5;
	mov.b32 	%r1304, 0;
	mov.b64 	%rd340, 0;
	mov.u64 	%rd309, __cudart_i2opi_f;
	mov.u32 	%r1303, %r1;
$L__BB0_280:                            // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd310, %rd309, %rd340;
	ld.global.nc.u32 	%r1186, [%rd310];
	// begin inline asm
	{
	mad.lo.cc.u32   %r1184, %r1186, %r1187, %r1304;
	madc.hi.u32     %r1304, %r1186, %r1187,  0;
	}
	// end inline asm
	st.local.u32 	[%r1303], %r1184;
	add.s32 	%r1303, %r1303, 4;
	add.s64 	%rd340, %rd340, 4;
	setp.ne.s64 	%p221, %rd340, 24;
	@%p221 bra 	$L__BB0_280;
// %bb.281:
	st.local.u32 	[%r1+24], %r1304;
	shl.b32 	%r1189, %r417, 2;
	sub.s32 	%r422, %r1, %r1189;
	ld.local.u32 	%r423, [%r422+24];
	ld.local.u32 	%r424, [%r422+20];
	and.b32  	%r1191, %r441, 260046848;
	setp.eq.s32 	%p222, %r1191, 0;
	mov.u32 	%r1305, %r424;
	@%p222 bra 	$L__BB0_283;
// %bb.282:
	ld.local.u32 	%r1192, [%r422+16];
	shf.l.wrap.b32 	%r1305, %r1192, %r424, %r415;
$L__BB0_283:                            // %__internal_trig_reduction_slowpath.exit.i.i.i1226
	shf.l.wrap.b32 	%r1193, %r424, %r423, %r415;
	shr.u32 	%r1194, %r1193, 30;
	shf.l.wrap.b32 	%r1195, %r1305, %r1193, 2;
	shl.b32 	%r1196, %r1305, 2;
	shr.u32 	%r1197, %r1195, 31;
	add.s32 	%r1198, %r1197, %r1194;
	neg.s32 	%r1199, %r1198;
	setp.lt.s32 	%p223, %r441, 0;
	selp.b32 	%r1306, %r1199, %r1198, %p223;
	xor.b32  	%r1200, %r1195, %r441;
	shr.s32 	%r1201, %r1195, 31;
	xor.b32  	%r1202, %r1201, %r1195;
	xor.b32  	%r1203, %r1201, %r1196;
	cvt.u64.u32 	%rd311, %r1202;
	shl.b64 	%rd312, %rd311, 32;
	cvt.u64.u32 	%rd313, %r1203;
	or.b64  	%rd314, %rd312, %rd313;
	cvt.rn.f64.s64 	%fd47, %rd314;
	mul.f64 	%fd48, %fd47, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f898, %fd48;
	neg.f32 	%f899, %f898;
	setp.lt.s32 	%p224, %r1200, 0;
	selp.f32 	%f1108, %f899, %f898, %p224;
$L__BB0_284:                            // %__internal_trig_reduction_kernel.exit.i.i1237
	add.s32 	%r429, %r1306, 1;
	mul.rn.ftz.f32 	%f375, %f1108, %f1108;
	and.b32  	%r1205, %r1306, 1;
	setp.eq.b32 	%p225, %r1205, 1;
	selp.f32 	%f376, %f1108, 0f3F800000, %p225;
	mov.f32 	%f904, 0f00000000;
	fma.rn.ftz.f32 	%f377, %f375, %f376, %f904;
	mov.f32 	%f1111, 0fB94D4153;
	mov.f32 	%f1110, 0f3C0885E4;
	mov.f32 	%f1109, 0fBE2AAAA8;
	@%p225 bra 	$L__BB0_286;
// %bb.285:                             // %__internal_fmad.exit1.i.i.i1257
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f905, 0fBAB607ED;
	mov.f32 	%f906, 0f37CBAC00;
	fma.rn.ftz.f32 	%f1111, %f906, %f375, %f905;
	mov.f32 	%f1110, 0f3D2AAABB;
	mov.f32 	%f1109, 0fBEFFFFFF;
$L__BB0_286:                            // %__internal_fmad.exit2.i.i.i1245
	ld.param.u64 	%rd59, [triton_poi_fused_clone_6_param_2];
	.loc	1 54 24                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:54:24
	fma.rn.ftz.f32 	%f909, %f1111, %f375, %f1110;
	fma.rn.ftz.f32 	%f910, %f909, %f375, %f1109;
	fma.rn.ftz.f32 	%f1112, %f910, %f377, %f376;
	and.b32  	%r1206, %r429, 2;
	setp.eq.s32 	%p226, %r1206, 0;
	@%p226 bra 	$L__BB0_288;
// %bb.287:                             // %__internal_fmad.exit5.i.i.i1253
	.loc	1 0 24                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:24
	mov.f32 	%f912, 0fBF800000;
	fma.rn.ftz.f32 	%f1112, %f1112, %f912, %f904;
$L__BB0_288:                            // %__nv_cosf.exit1263
	.loc	1 60 25                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:25
	shl.b64 	%rd316, %rd1, 1;
	add.s64 	%rd315, %rd59, %rd316;
	.loc	1 30 63                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:63
	mov.b32 	{%rs57, %rs58}, %r442;
	cvt.f32.f16 	%f913, %rs57;
	cvt.f32.f16 	%f914, %rs58;
	.loc	1 37 13                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:37:13
	neg.f32 	%f915, %f1002;
	fma.rn.f32 	%f916, %f915, %f914, 0f00000000;
	neg.f32 	%f917, %f997;
	fma.rn.f32 	%f918, %f917, %f913, 0f00000000;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f919, %f918, 0f00000000, %p1;
	selp.f32 	%f920, %f916, 0f00000000, %p1;
	.loc	1 43 62                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:62
	mov.b32 	{%rs59, %rs60}, %r749;
	cvt.f32.f16 	%f921, %rs59;
	cvt.f32.f16 	%f922, %rs60;
	.loc	1 49 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:49:20
	mul.f32 	%f923, %f1042, %f922;
	mul.f32 	%f924, %f1037, %f921;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f925, %f924, 0f00000000, %p82;
	selp.f32 	%f926, %f923, 0f00000000, %p82;
	.loc	1 53 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:53:20
	add.f32 	%f927, %f920, %f926;
	add.f32 	%f928, %f919, %f925;
	.loc	1 25 45                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:45
	mov.b32 	{%rs61, %rs62}, %r430;
	cvt.f32.f16 	%f929, %rs62;
	cvt.f32.f16 	%f930, %rs61;
	.loc	1 59 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:59:20
	fma.rn.f32 	%f931, %f1077, %f930, %f928;
	fma.rn.f32 	%f932, %f1082, %f929, %f927;
	.loc	1 60 37                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:37
	cvt.rn.f16x2.f32 	%r1207, %f932, %f931;
	.loc	1 30 63                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:63
	mov.b32 	{%rs63, %rs64}, %r443;
	cvt.f32.f16 	%f933, %rs63;
	cvt.f32.f16 	%f934, %rs64;
	.loc	1 37 13                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:37:13
	neg.f32 	%f935, %f1012;
	fma.rn.f32 	%f936, %f935, %f934, 0f00000000;
	neg.f32 	%f937, %f1007;
	fma.rn.f32 	%f938, %f937, %f933, 0f00000000;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f939, %f938, 0f00000000, %p1;
	selp.f32 	%f940, %f936, 0f00000000, %p1;
	.loc	1 43 62                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:62
	mov.b32 	{%rs65, %rs66}, %r750;
	cvt.f32.f16 	%f941, %rs65;
	cvt.f32.f16 	%f942, %rs66;
	.loc	1 49 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:49:20
	mul.f32 	%f943, %f1052, %f942;
	mul.f32 	%f944, %f1047, %f941;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f945, %f944, 0f00000000, %p82;
	selp.f32 	%f946, %f943, 0f00000000, %p82;
	.loc	1 53 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:53:20
	add.f32 	%f947, %f940, %f946;
	add.f32 	%f948, %f939, %f945;
	.loc	1 25 45                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:45
	mov.b32 	{%rs67, %rs68}, %r431;
	cvt.f32.f16 	%f949, %rs68;
	cvt.f32.f16 	%f950, %rs67;
	.loc	1 59 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:59:20
	fma.rn.f32 	%f951, %f1087, %f950, %f948;
	fma.rn.f32 	%f952, %f1092, %f949, %f947;
	.loc	1 60 37                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:37
	cvt.rn.f16x2.f32 	%r1208, %f952, %f951;
	.loc	1 30 63                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:63
	mov.b32 	{%rs69, %rs70}, %r444;
	cvt.f32.f16 	%f953, %rs69;
	cvt.f32.f16 	%f954, %rs70;
	.loc	1 37 13                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:37:13
	neg.f32 	%f955, %f1022;
	fma.rn.f32 	%f956, %f955, %f954, 0f00000000;
	neg.f32 	%f957, %f1017;
	fma.rn.f32 	%f958, %f957, %f953, 0f00000000;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f959, %f958, 0f00000000, %p1;
	selp.f32 	%f960, %f956, 0f00000000, %p1;
	.loc	1 43 62                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:62
	mov.b32 	{%rs71, %rs72}, %r751;
	cvt.f32.f16 	%f961, %rs71;
	cvt.f32.f16 	%f962, %rs72;
	.loc	1 49 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:49:20
	mul.f32 	%f963, %f1062, %f962;
	mul.f32 	%f964, %f1057, %f961;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f965, %f964, 0f00000000, %p82;
	selp.f32 	%f966, %f963, 0f00000000, %p82;
	.loc	1 53 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:53:20
	add.f32 	%f967, %f960, %f966;
	add.f32 	%f968, %f959, %f965;
	.loc	1 25 45                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:45
	mov.b32 	{%rs73, %rs74}, %r432;
	cvt.f32.f16 	%f969, %rs74;
	cvt.f32.f16 	%f970, %rs73;
	.loc	1 59 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:59:20
	fma.rn.f32 	%f971, %f1097, %f970, %f968;
	fma.rn.f32 	%f972, %f1102, %f969, %f967;
	.loc	1 60 37                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:37
	cvt.rn.f16x2.f32 	%r1209, %f972, %f971;
	.loc	1 30 63                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:30:63
	mov.b32 	{%rs75, %rs76}, %r445;
	cvt.f32.f16 	%f973, %rs75;
	cvt.f32.f16 	%f974, %rs76;
	.loc	1 37 13                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:37:13
	neg.f32 	%f975, %f1032;
	fma.rn.f32 	%f976, %f975, %f974, 0f00000000;
	neg.f32 	%f977, %f1027;
	fma.rn.f32 	%f978, %f977, %f973, 0f00000000;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f979, %f978, 0f00000000, %p1;
	selp.f32 	%f980, %f976, 0f00000000, %p1;
	.loc	1 43 62                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:43:62
	mov.b32 	{%rs77, %rs78}, %r752;
	cvt.f32.f16 	%f981, %rs77;
	cvt.f32.f16 	%f982, %rs78;
	.loc	1 49 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:49:20
	mul.f32 	%f983, %f1072, %f982;
	mul.f32 	%f984, %f1067, %f981;
	.loc	1 0 0                           // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:0:0
	selp.f32 	%f985, %f984, 0f00000000, %p82;
	selp.f32 	%f986, %f983, 0f00000000, %p82;
	.loc	1 53 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:53:20
	add.f32 	%f987, %f980, %f986;
	add.f32 	%f988, %f979, %f985;
	.loc	1 25 45                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:25:45
	mov.b32 	{%rs79, %rs80}, %r433;
	cvt.f32.f16 	%f989, %rs80;
	cvt.f32.f16 	%f990, %rs79;
	.loc	1 59 20                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:59:20
	fma.rn.f32 	%f991, %f1107, %f990, %f988;
	fma.rn.f32 	%f992, %f1112, %f989, %f987;
	.loc	1 60 37                         // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:37
	cvt.rn.f16x2.f32 	%r1210, %f992, %f991;
	// begin inline asm
	st.global.v4.b32 [ %rd315 + 0 ], { %r1207, %r1208, %r1209, %r1210 };
	// end inline asm
	.loc	1 60 4                          // chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py:60:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/tmp/torchinductor_root/hq/chq6bi6dvtpwhup4zzai4hvirok6ccb2hkiqqgljwyaarndo72kz.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 104                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x61 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 104
.b8 113
.b8 54
.b8 98
.b8 105
.b8 54
.b8 100
.b8 118
.b8 116
.b8 112
.b8 119
.b8 104
.b8 117
.b8 112
.b8 52
.b8 122
.b8 122
.b8 97
.b8 105
.b8 52
.b8 104
.b8 118
.b8 105
.b8 114
.b8 111
.b8 107
.b8 54
.b8 99
.b8 99
.b8 98
.b8 50
.b8 104
.b8 107
.b8 105
.b8 113
.b8 113
.b8 103
.b8 108
.b8 106
.b8 119
.b8 121
.b8 97
.b8 97
.b8 114
.b8 110
.b8 100
.b8 111
.b8 55
.b8 50
.b8 107
.b8 122
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 116
.b8 109
.b8 112
.b8 47
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 114
.b8 111
.b8 111
.b8 116
.b8 47
.b8 104
.b8 113
.b8 0
	}
	.section	.debug_macinfo	{	}
